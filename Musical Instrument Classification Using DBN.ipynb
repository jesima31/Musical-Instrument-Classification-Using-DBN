{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "681a19b0",
      "metadata": {
        "id": "681a19b0",
        "outputId": "82b6deb3-3647-4c2c-c503-21dbea33f9be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 43.599544\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 42.976945\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 42.911898\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 42.992147\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 43.180143\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 43.271735\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 43.482608\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 43.651730\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 44.033955\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 43.820545\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 9.997884\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 6.580758\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 5.279427\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 4.759158\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 4.508030\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 4.248742\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 4.053245\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 3.889613\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 3.757097\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 3.596914\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss 2.037231\n",
            ">> Epoch 1 finished \tANN training loss 2.530553\n",
            ">> Epoch 2 finished \tANN training loss 1.891335\n",
            ">> Epoch 3 finished \tANN training loss 1.708371\n",
            ">> Epoch 4 finished \tANN training loss 1.705091\n",
            ">> Epoch 5 finished \tANN training loss 1.508305\n",
            ">> Epoch 6 finished \tANN training loss 1.467426\n",
            ">> Epoch 7 finished \tANN training loss 1.478177\n",
            ">> Epoch 8 finished \tANN training loss 1.308451\n",
            ">> Epoch 9 finished \tANN training loss 1.238117\n",
            ">> Epoch 10 finished \tANN training loss 1.209970\n",
            ">> Epoch 11 finished \tANN training loss 1.123635\n",
            ">> Epoch 12 finished \tANN training loss 1.187243\n",
            ">> Epoch 13 finished \tANN training loss 1.089304\n",
            ">> Epoch 14 finished \tANN training loss 1.323144\n",
            ">> Epoch 15 finished \tANN training loss 1.095376\n",
            ">> Epoch 16 finished \tANN training loss 1.378574\n",
            ">> Epoch 17 finished \tANN training loss 1.214751\n",
            ">> Epoch 18 finished \tANN training loss 1.263677\n",
            ">> Epoch 19 finished \tANN training loss 0.960594\n",
            ">> Epoch 20 finished \tANN training loss 0.875466\n",
            ">> Epoch 21 finished \tANN training loss 0.955809\n",
            ">> Epoch 22 finished \tANN training loss 0.862924\n",
            ">> Epoch 23 finished \tANN training loss 0.911252\n",
            ">> Epoch 24 finished \tANN training loss 0.805782\n",
            ">> Epoch 25 finished \tANN training loss 0.961703\n",
            ">> Epoch 26 finished \tANN training loss 0.942794\n",
            ">> Epoch 27 finished \tANN training loss 0.728192\n",
            ">> Epoch 28 finished \tANN training loss 0.667025\n",
            ">> Epoch 29 finished \tANN training loss 0.763087\n",
            ">> Epoch 30 finished \tANN training loss 0.751965\n",
            ">> Epoch 31 finished \tANN training loss 0.928952\n",
            ">> Epoch 32 finished \tANN training loss 0.774827\n",
            ">> Epoch 33 finished \tANN training loss 0.587178\n",
            ">> Epoch 34 finished \tANN training loss 0.665162\n",
            ">> Epoch 35 finished \tANN training loss 0.776877\n",
            ">> Epoch 36 finished \tANN training loss 0.565274\n",
            ">> Epoch 37 finished \tANN training loss 0.569235\n",
            ">> Epoch 38 finished \tANN training loss 0.596031\n",
            ">> Epoch 39 finished \tANN training loss 0.577027\n",
            ">> Epoch 40 finished \tANN training loss 0.553418\n",
            ">> Epoch 41 finished \tANN training loss 0.620908\n",
            ">> Epoch 42 finished \tANN training loss 0.571162\n",
            ">> Epoch 43 finished \tANN training loss 0.526746\n",
            ">> Epoch 44 finished \tANN training loss 0.530537\n",
            ">> Epoch 45 finished \tANN training loss 0.608071\n",
            ">> Epoch 46 finished \tANN training loss 0.593929\n",
            ">> Epoch 47 finished \tANN training loss 0.494764\n",
            ">> Epoch 48 finished \tANN training loss 0.487681\n",
            ">> Epoch 49 finished \tANN training loss 0.564391\n",
            ">> Epoch 50 finished \tANN training loss 0.523037\n",
            ">> Epoch 51 finished \tANN training loss 0.474280\n",
            ">> Epoch 52 finished \tANN training loss 0.510944\n",
            ">> Epoch 53 finished \tANN training loss 0.475152\n",
            ">> Epoch 54 finished \tANN training loss 0.486462\n",
            ">> Epoch 55 finished \tANN training loss 0.456293\n",
            ">> Epoch 56 finished \tANN training loss 0.475490\n",
            ">> Epoch 57 finished \tANN training loss 0.393183\n",
            ">> Epoch 58 finished \tANN training loss 0.413918\n",
            ">> Epoch 59 finished \tANN training loss 0.437031\n",
            ">> Epoch 60 finished \tANN training loss 0.432454\n",
            ">> Epoch 61 finished \tANN training loss 0.679555\n",
            ">> Epoch 62 finished \tANN training loss 0.398085\n",
            ">> Epoch 63 finished \tANN training loss 0.353334\n",
            ">> Epoch 64 finished \tANN training loss 0.425641\n",
            ">> Epoch 65 finished \tANN training loss 0.476713\n",
            ">> Epoch 66 finished \tANN training loss 0.380425\n",
            ">> Epoch 67 finished \tANN training loss 0.410107\n",
            ">> Epoch 68 finished \tANN training loss 0.411578\n",
            ">> Epoch 69 finished \tANN training loss 0.321684\n",
            ">> Epoch 70 finished \tANN training loss 0.305066\n",
            ">> Epoch 71 finished \tANN training loss 0.314879\n",
            ">> Epoch 72 finished \tANN training loss 0.280945\n",
            ">> Epoch 73 finished \tANN training loss 0.254134\n",
            ">> Epoch 74 finished \tANN training loss 0.246903\n",
            ">> Epoch 75 finished \tANN training loss 0.234316\n",
            ">> Epoch 76 finished \tANN training loss 0.282456\n",
            ">> Epoch 77 finished \tANN training loss 0.230592\n",
            ">> Epoch 78 finished \tANN training loss 0.209004\n",
            ">> Epoch 79 finished \tANN training loss 0.334618\n",
            ">> Epoch 80 finished \tANN training loss 0.222582\n",
            ">> Epoch 81 finished \tANN training loss 0.204601\n",
            ">> Epoch 82 finished \tANN training loss 0.203881\n",
            ">> Epoch 83 finished \tANN training loss 0.235314\n",
            ">> Epoch 84 finished \tANN training loss 0.269530\n",
            ">> Epoch 85 finished \tANN training loss 0.205300\n",
            ">> Epoch 86 finished \tANN training loss 0.197776\n",
            ">> Epoch 87 finished \tANN training loss 0.294495\n",
            ">> Epoch 88 finished \tANN training loss 0.181181\n",
            ">> Epoch 89 finished \tANN training loss 0.174272\n",
            ">> Epoch 90 finished \tANN training loss 0.204566\n",
            ">> Epoch 91 finished \tANN training loss 0.211796\n",
            ">> Epoch 92 finished \tANN training loss 0.196329\n",
            ">> Epoch 93 finished \tANN training loss 0.162750\n",
            ">> Epoch 94 finished \tANN training loss 0.172406\n",
            ">> Epoch 95 finished \tANN training loss 0.191705\n",
            ">> Epoch 96 finished \tANN training loss 0.195645\n",
            ">> Epoch 97 finished \tANN training loss 0.226054\n",
            ">> Epoch 98 finished \tANN training loss 0.160112\n",
            ">> Epoch 99 finished \tANN training loss 0.182126\n",
            "[END] Fine tuning step\n",
            "\n",
            "Accuracy: 0.926471\n",
            "Confusion Matrix:\n",
            " [[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  2  0 10  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0 13]]\n"
          ]
        }
      ],
      "source": [
        "#case1\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(3529)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "\n",
        "dataset = pd.read_csv(\"Instruments.csv\")\n",
        "dataset = dataset.drop([\"File Name\"], axis=1)\n",
        "\n",
        "le = LabelEncoder()\n",
        "dataset['Instrument'] = le.fit_transform(dataset['Instrument'])\n",
        "\n",
        "X = np.array(dataset.drop([\"Instrument\"], axis=1))\n",
        "Y = np.array(dataset.Instrument.values)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[128, 128],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.4,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='sigmoid',\n",
        "                                         dropout_p=0.05)\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print('\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fb68624",
      "metadata": {
        "id": "9fb68624",
        "outputId": "ee0b3184-d8ac-4bb6-e2ec-89ccf55c2e8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 43.782150\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 42.928241\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 42.655945\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 42.693698\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 42.927321\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 43.209267\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 43.481772\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 43.672546\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 44.062125\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 43.818609\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 10.392400\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 6.700058\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 5.298466\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 4.796281\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 4.568461\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 4.397188\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 4.223192\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 4.061265\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 4.007226\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 3.796173\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss 2.048473\n",
            ">> Epoch 1 finished \tANN training loss 2.555068\n",
            ">> Epoch 2 finished \tANN training loss 1.943166\n",
            ">> Epoch 3 finished \tANN training loss 1.845320\n",
            ">> Epoch 4 finished \tANN training loss 1.839659\n",
            ">> Epoch 5 finished \tANN training loss 1.595223\n",
            ">> Epoch 6 finished \tANN training loss 1.597985\n",
            ">> Epoch 7 finished \tANN training loss 1.599554\n",
            ">> Epoch 8 finished \tANN training loss 1.423829\n",
            ">> Epoch 9 finished \tANN training loss 1.343475\n",
            ">> Epoch 10 finished \tANN training loss 1.404213\n",
            ">> Epoch 11 finished \tANN training loss 1.280437\n",
            ">> Epoch 12 finished \tANN training loss 1.263719\n",
            ">> Epoch 13 finished \tANN training loss 1.295932\n",
            ">> Epoch 14 finished \tANN training loss 1.376567\n",
            ">> Epoch 15 finished \tANN training loss 1.238679\n",
            ">> Epoch 16 finished \tANN training loss 1.426598\n",
            ">> Epoch 17 finished \tANN training loss 1.251217\n",
            ">> Epoch 18 finished \tANN training loss 1.269683\n",
            ">> Epoch 19 finished \tANN training loss 1.157708\n",
            ">> Epoch 20 finished \tANN training loss 1.030899\n",
            ">> Epoch 21 finished \tANN training loss 1.006503\n",
            ">> Epoch 22 finished \tANN training loss 1.036715\n",
            ">> Epoch 23 finished \tANN training loss 1.050383\n",
            ">> Epoch 24 finished \tANN training loss 0.966062\n",
            ">> Epoch 25 finished \tANN training loss 1.019315\n",
            ">> Epoch 26 finished \tANN training loss 0.969783\n",
            ">> Epoch 27 finished \tANN training loss 0.830298\n",
            ">> Epoch 28 finished \tANN training loss 0.992098\n",
            ">> Epoch 29 finished \tANN training loss 0.902074\n",
            ">> Epoch 30 finished \tANN training loss 0.933671\n",
            ">> Epoch 31 finished \tANN training loss 1.063265\n",
            ">> Epoch 32 finished \tANN training loss 0.949229\n",
            ">> Epoch 33 finished \tANN training loss 0.699161\n",
            ">> Epoch 34 finished \tANN training loss 0.749050\n",
            ">> Epoch 35 finished \tANN training loss 0.831956\n",
            ">> Epoch 36 finished \tANN training loss 0.697498\n",
            ">> Epoch 37 finished \tANN training loss 0.649158\n",
            ">> Epoch 38 finished \tANN training loss 0.676074\n",
            ">> Epoch 39 finished \tANN training loss 0.642122\n",
            ">> Epoch 40 finished \tANN training loss 0.669421\n",
            ">> Epoch 41 finished \tANN training loss 0.657683\n",
            ">> Epoch 42 finished \tANN training loss 0.625996\n",
            ">> Epoch 43 finished \tANN training loss 0.676108\n",
            ">> Epoch 44 finished \tANN training loss 0.635477\n",
            ">> Epoch 45 finished \tANN training loss 0.625749\n",
            ">> Epoch 46 finished \tANN training loss 0.692621\n",
            ">> Epoch 47 finished \tANN training loss 0.539687\n",
            ">> Epoch 48 finished \tANN training loss 0.588893\n",
            ">> Epoch 49 finished \tANN training loss 0.591711\n",
            ">> Epoch 50 finished \tANN training loss 0.604669\n",
            ">> Epoch 51 finished \tANN training loss 0.519620\n",
            ">> Epoch 52 finished \tANN training loss 0.542684\n",
            ">> Epoch 53 finished \tANN training loss 0.644590\n",
            ">> Epoch 54 finished \tANN training loss 0.529678\n",
            ">> Epoch 55 finished \tANN training loss 0.498389\n",
            ">> Epoch 56 finished \tANN training loss 0.540913\n",
            ">> Epoch 57 finished \tANN training loss 0.478119\n",
            ">> Epoch 58 finished \tANN training loss 0.516382\n",
            ">> Epoch 59 finished \tANN training loss 0.503232\n",
            ">> Epoch 60 finished \tANN training loss 0.565553\n",
            ">> Epoch 61 finished \tANN training loss 0.475282\n",
            ">> Epoch 62 finished \tANN training loss 0.508320\n",
            ">> Epoch 63 finished \tANN training loss 0.459403\n",
            ">> Epoch 64 finished \tANN training loss 0.476170\n",
            ">> Epoch 65 finished \tANN training loss 0.493728\n",
            ">> Epoch 66 finished \tANN training loss 0.453150\n",
            ">> Epoch 67 finished \tANN training loss 0.437306\n",
            ">> Epoch 68 finished \tANN training loss 0.524561\n",
            ">> Epoch 69 finished \tANN training loss 0.456132\n",
            ">> Epoch 70 finished \tANN training loss 0.408970\n",
            ">> Epoch 71 finished \tANN training loss 0.424216\n",
            ">> Epoch 72 finished \tANN training loss 0.470458\n",
            ">> Epoch 73 finished \tANN training loss 0.384628\n",
            ">> Epoch 74 finished \tANN training loss 0.405904\n",
            ">> Epoch 75 finished \tANN training loss 0.378710\n",
            ">> Epoch 76 finished \tANN training loss 0.527515\n",
            ">> Epoch 77 finished \tANN training loss 0.385493\n",
            ">> Epoch 78 finished \tANN training loss 0.355130\n",
            ">> Epoch 79 finished \tANN training loss 0.371594\n",
            ">> Epoch 80 finished \tANN training loss 0.397235\n",
            ">> Epoch 81 finished \tANN training loss 0.391941\n",
            ">> Epoch 82 finished \tANN training loss 0.361381\n",
            ">> Epoch 83 finished \tANN training loss 0.392323\n",
            ">> Epoch 84 finished \tANN training loss 0.374375\n",
            ">> Epoch 85 finished \tANN training loss 0.363242\n",
            ">> Epoch 86 finished \tANN training loss 0.374447\n",
            ">> Epoch 87 finished \tANN training loss 0.403555\n",
            ">> Epoch 88 finished \tANN training loss 0.329691\n",
            ">> Epoch 89 finished \tANN training loss 0.334911\n",
            ">> Epoch 90 finished \tANN training loss 0.342292\n",
            ">> Epoch 91 finished \tANN training loss 0.330106\n",
            ">> Epoch 92 finished \tANN training loss 0.310393\n",
            ">> Epoch 93 finished \tANN training loss 0.314418\n",
            ">> Epoch 94 finished \tANN training loss 0.358456\n",
            ">> Epoch 95 finished \tANN training loss 0.327619\n",
            ">> Epoch 96 finished \tANN training loss 0.293542\n",
            ">> Epoch 97 finished \tANN training loss 0.355162\n",
            ">> Epoch 98 finished \tANN training loss 0.440505\n",
            ">> Epoch 99 finished \tANN training loss 0.372699\n",
            "[END] Fine tuning step\n",
            "\n",
            "Accuracy: 0.852941\n",
            "Confusion Matrix:\n",
            " [[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  5  0  6  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0 14  0  0  0  0  0  0]\n",
            " [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0]\n",
            " [ 0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  1 12]]\n"
          ]
        }
      ],
      "source": [
        "#case2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(3529)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "\n",
        "dataset = pd.read_csv(\"Instruments.csv\")\n",
        "dataset = dataset.drop([\"File Name\"], axis=1)\n",
        "\n",
        "le = LabelEncoder()\n",
        "dataset['Instrument'] = le.fit_transform(dataset['Instrument'])\n",
        "\n",
        "X = np.array(dataset.drop([\"Instrument\"], axis=1))\n",
        "Y = np.array(dataset.Instrument.values)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[128, 128],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.4,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='sigmoid',\n",
        "                                         dropout_p=0.1)\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print('\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44c2874c",
      "metadata": {
        "id": "44c2874c",
        "outputId": "95a6f6c8-024e-4246-edc1-15d8638d49ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 43.579861\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 42.648378\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 42.461308\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 42.441174\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 42.601003\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 42.680919\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 42.801097\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 42.832580\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 43.133236\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 42.917262\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 10.114342\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 6.303115\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 5.110419\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 4.639163\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 4.457079\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 4.256772\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 4.115946\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 3.963893\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 3.893830\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 3.757128\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss 2.084739\n",
            ">> Epoch 1 finished \tANN training loss 2.693096\n",
            ">> Epoch 2 finished \tANN training loss 2.023645\n",
            ">> Epoch 3 finished \tANN training loss 1.936663\n",
            ">> Epoch 4 finished \tANN training loss 1.938408\n",
            ">> Epoch 5 finished \tANN training loss 1.711225\n",
            ">> Epoch 6 finished \tANN training loss 1.646958\n",
            ">> Epoch 7 finished \tANN training loss 1.562639\n",
            ">> Epoch 8 finished \tANN training loss 1.439193\n",
            ">> Epoch 9 finished \tANN training loss 1.368606\n",
            ">> Epoch 10 finished \tANN training loss 1.421918\n",
            ">> Epoch 11 finished \tANN training loss 1.213603\n",
            ">> Epoch 12 finished \tANN training loss 1.258609\n",
            ">> Epoch 13 finished \tANN training loss 1.207161\n",
            ">> Epoch 14 finished \tANN training loss 1.266410\n",
            ">> Epoch 15 finished \tANN training loss 1.160871\n",
            ">> Epoch 16 finished \tANN training loss 1.171288\n",
            ">> Epoch 17 finished \tANN training loss 1.218048\n",
            ">> Epoch 18 finished \tANN training loss 1.098999\n",
            ">> Epoch 19 finished \tANN training loss 1.062969\n",
            ">> Epoch 20 finished \tANN training loss 0.980961\n",
            ">> Epoch 21 finished \tANN training loss 1.051329\n",
            ">> Epoch 22 finished \tANN training loss 0.966101\n",
            ">> Epoch 23 finished \tANN training loss 0.999138\n",
            ">> Epoch 24 finished \tANN training loss 0.893240\n",
            ">> Epoch 25 finished \tANN training loss 0.988844\n",
            ">> Epoch 26 finished \tANN training loss 0.925951\n",
            ">> Epoch 27 finished \tANN training loss 0.834280\n",
            ">> Epoch 28 finished \tANN training loss 0.842872\n",
            ">> Epoch 29 finished \tANN training loss 0.883498\n",
            ">> Epoch 30 finished \tANN training loss 0.845186\n",
            ">> Epoch 31 finished \tANN training loss 0.978131\n",
            ">> Epoch 32 finished \tANN training loss 0.832040\n",
            ">> Epoch 33 finished \tANN training loss 0.768827\n",
            ">> Epoch 34 finished \tANN training loss 0.794108\n",
            ">> Epoch 35 finished \tANN training loss 0.798608\n",
            ">> Epoch 36 finished \tANN training loss 0.782939\n",
            ">> Epoch 37 finished \tANN training loss 0.712071\n",
            ">> Epoch 38 finished \tANN training loss 0.737106\n",
            ">> Epoch 39 finished \tANN training loss 0.726010\n",
            ">> Epoch 40 finished \tANN training loss 0.737025\n",
            ">> Epoch 41 finished \tANN training loss 0.692586\n",
            ">> Epoch 42 finished \tANN training loss 0.695108\n",
            ">> Epoch 43 finished \tANN training loss 0.693935\n",
            ">> Epoch 44 finished \tANN training loss 0.676004\n",
            ">> Epoch 45 finished \tANN training loss 0.715704\n",
            ">> Epoch 46 finished \tANN training loss 0.777306\n",
            ">> Epoch 47 finished \tANN training loss 0.686728\n",
            ">> Epoch 48 finished \tANN training loss 0.622795\n",
            ">> Epoch 49 finished \tANN training loss 0.752038\n",
            ">> Epoch 50 finished \tANN training loss 0.640022\n",
            ">> Epoch 51 finished \tANN training loss 0.600058\n",
            ">> Epoch 52 finished \tANN training loss 0.623110\n",
            ">> Epoch 53 finished \tANN training loss 0.620080\n",
            ">> Epoch 54 finished \tANN training loss 0.608240\n",
            ">> Epoch 55 finished \tANN training loss 0.569297\n",
            ">> Epoch 56 finished \tANN training loss 0.614504\n",
            ">> Epoch 57 finished \tANN training loss 0.563499\n",
            ">> Epoch 58 finished \tANN training loss 0.564582\n",
            ">> Epoch 59 finished \tANN training loss 0.547316\n",
            ">> Epoch 60 finished \tANN training loss 0.652366\n",
            ">> Epoch 61 finished \tANN training loss 0.645404\n",
            ">> Epoch 62 finished \tANN training loss 0.556507\n",
            ">> Epoch 63 finished \tANN training loss 0.508432\n",
            ">> Epoch 64 finished \tANN training loss 0.480117\n",
            ">> Epoch 65 finished \tANN training loss 0.549756\n",
            ">> Epoch 66 finished \tANN training loss 0.559426\n",
            ">> Epoch 67 finished \tANN training loss 0.482389\n",
            ">> Epoch 68 finished \tANN training loss 0.614246\n",
            ">> Epoch 69 finished \tANN training loss 0.505947\n",
            ">> Epoch 70 finished \tANN training loss 0.450987\n",
            ">> Epoch 71 finished \tANN training loss 0.441960\n",
            ">> Epoch 72 finished \tANN training loss 0.459380\n",
            ">> Epoch 73 finished \tANN training loss 0.435842\n",
            ">> Epoch 74 finished \tANN training loss 0.411909\n",
            ">> Epoch 75 finished \tANN training loss 0.453610\n",
            ">> Epoch 76 finished \tANN training loss 0.553233\n",
            ">> Epoch 77 finished \tANN training loss 0.444737\n",
            ">> Epoch 78 finished \tANN training loss 0.420708\n",
            ">> Epoch 79 finished \tANN training loss 0.425887\n",
            ">> Epoch 80 finished \tANN training loss 0.473440\n",
            ">> Epoch 81 finished \tANN training loss 0.386143\n",
            ">> Epoch 82 finished \tANN training loss 0.395802\n",
            ">> Epoch 83 finished \tANN training loss 0.395745\n",
            ">> Epoch 84 finished \tANN training loss 0.383671\n",
            ">> Epoch 85 finished \tANN training loss 0.395391\n",
            ">> Epoch 86 finished \tANN training loss 0.452694\n",
            ">> Epoch 87 finished \tANN training loss 0.375133\n",
            ">> Epoch 88 finished \tANN training loss 0.394350\n",
            ">> Epoch 89 finished \tANN training loss 0.354372\n",
            ">> Epoch 90 finished \tANN training loss 0.359927\n",
            ">> Epoch 91 finished \tANN training loss 0.397791\n",
            ">> Epoch 92 finished \tANN training loss 0.375923\n",
            ">> Epoch 93 finished \tANN training loss 0.343724\n",
            ">> Epoch 94 finished \tANN training loss 0.371028\n",
            ">> Epoch 95 finished \tANN training loss 0.330187\n",
            ">> Epoch 96 finished \tANN training loss 0.350419\n",
            ">> Epoch 97 finished \tANN training loss 0.356131\n",
            ">> Epoch 98 finished \tANN training loss 0.326913\n",
            ">> Epoch 99 finished \tANN training loss 0.425495\n",
            "[END] Fine tuning step\n",
            "\n",
            "Accuracy: 0.813725\n",
            "Confusion Matrix:\n",
            " [[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 10  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  5  0  6  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  0]\n",
            " [ 0  0  8  0  0  0  0  0  0  0  0  2  0  0  0  0  0]\n",
            " [ 0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  2  0  0  0  0  0  0  0 14  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  3]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0 11  0]\n",
            " [ 0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  5  8]]\n"
          ]
        }
      ],
      "source": [
        "#case3\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(3529)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "\n",
        "dataset = pd.read_csv(\"Instruments.csv\")\n",
        "dataset = dataset.drop([\"File Name\"], axis=1)\n",
        "\n",
        "le = LabelEncoder()\n",
        "dataset['Instrument'] = le.fit_transform(dataset['Instrument'])\n",
        "\n",
        "X = np.array(dataset.drop([\"Instrument\"], axis=1))\n",
        "Y = np.array(dataset.Instrument.values)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[128, 128],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.4,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='sigmoid',\n",
        "                                         dropout_p=0.2)\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print('\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c86b7c1e",
      "metadata": {
        "id": "c86b7c1e",
        "outputId": "98869754-c0e1-41bc-912b-c1c1308ca421"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 41.815052\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 40.867323\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 40.931374\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 41.054906\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 41.300267\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 41.585167\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 41.854288\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 42.041261\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 42.439653\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 42.228696\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 14.240275\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 11.222238\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 10.207335\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 9.561489\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 8.943264\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 8.386539\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 8.092778\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 7.484471\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 7.351327\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 6.951092\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss 3.202194\n",
            ">> Epoch 1 finished \tANN training loss 2.924797\n",
            ">> Epoch 2 finished \tANN training loss 1.900054\n",
            ">> Epoch 3 finished \tANN training loss 1.650820\n",
            ">> Epoch 4 finished \tANN training loss 1.939302\n",
            ">> Epoch 5 finished \tANN training loss 1.507740\n",
            ">> Epoch 6 finished \tANN training loss 1.211567\n",
            ">> Epoch 7 finished \tANN training loss 1.176030\n",
            ">> Epoch 8 finished \tANN training loss 1.068863\n",
            ">> Epoch 9 finished \tANN training loss 1.129925\n",
            ">> Epoch 10 finished \tANN training loss 0.909382\n",
            ">> Epoch 11 finished \tANN training loss 0.868795\n",
            ">> Epoch 12 finished \tANN training loss 0.739042\n",
            ">> Epoch 13 finished \tANN training loss 0.740777\n",
            ">> Epoch 14 finished \tANN training loss 0.865510\n",
            ">> Epoch 15 finished \tANN training loss 0.884911\n",
            ">> Epoch 16 finished \tANN training loss 0.799987\n",
            ">> Epoch 17 finished \tANN training loss 0.885908\n",
            ">> Epoch 18 finished \tANN training loss 0.910038\n",
            ">> Epoch 19 finished \tANN training loss 0.683045\n",
            ">> Epoch 20 finished \tANN training loss 0.647366\n",
            ">> Epoch 21 finished \tANN training loss 0.774005\n",
            ">> Epoch 22 finished \tANN training loss 0.817662\n",
            ">> Epoch 23 finished \tANN training loss 1.131454\n",
            ">> Epoch 24 finished \tANN training loss 0.628250\n",
            ">> Epoch 25 finished \tANN training loss 0.929307\n",
            ">> Epoch 26 finished \tANN training loss 0.680526\n",
            ">> Epoch 27 finished \tANN training loss 0.494073\n",
            ">> Epoch 28 finished \tANN training loss 0.480094\n",
            ">> Epoch 29 finished \tANN training loss 0.503564\n",
            ">> Epoch 30 finished \tANN training loss 0.712954\n",
            ">> Epoch 31 finished \tANN training loss 1.083019\n",
            ">> Epoch 32 finished \tANN training loss 1.127132\n",
            ">> Epoch 33 finished \tANN training loss 0.403434\n",
            ">> Epoch 34 finished \tANN training loss 0.413601\n",
            ">> Epoch 35 finished \tANN training loss 0.906533\n",
            ">> Epoch 36 finished \tANN training loss 0.415442\n",
            ">> Epoch 37 finished \tANN training loss 0.370264\n",
            ">> Epoch 38 finished \tANN training loss 0.485404\n",
            ">> Epoch 39 finished \tANN training loss 0.346662\n",
            ">> Epoch 40 finished \tANN training loss 0.347488\n",
            ">> Epoch 41 finished \tANN training loss 0.437101\n",
            ">> Epoch 42 finished \tANN training loss 0.361671\n",
            ">> Epoch 43 finished \tANN training loss 0.405144\n",
            ">> Epoch 44 finished \tANN training loss 0.286435\n",
            ">> Epoch 45 finished \tANN training loss 0.376581\n",
            ">> Epoch 46 finished \tANN training loss 0.357732\n",
            ">> Epoch 47 finished \tANN training loss 0.263748\n",
            ">> Epoch 48 finished \tANN training loss 0.259885\n",
            ">> Epoch 49 finished \tANN training loss 0.597352\n",
            ">> Epoch 50 finished \tANN training loss 0.336615\n",
            ">> Epoch 51 finished \tANN training loss 0.414701\n",
            ">> Epoch 52 finished \tANN training loss 0.357649\n",
            ">> Epoch 53 finished \tANN training loss 0.328534\n",
            ">> Epoch 54 finished \tANN training loss 0.307624\n",
            ">> Epoch 55 finished \tANN training loss 0.565138\n",
            ">> Epoch 56 finished \tANN training loss 0.333186\n",
            ">> Epoch 57 finished \tANN training loss 0.229221\n",
            ">> Epoch 58 finished \tANN training loss 0.283868\n",
            ">> Epoch 59 finished \tANN training loss 0.274469\n",
            ">> Epoch 60 finished \tANN training loss 0.193745\n",
            ">> Epoch 61 finished \tANN training loss 0.343308\n",
            ">> Epoch 62 finished \tANN training loss 0.250944\n",
            ">> Epoch 63 finished \tANN training loss 0.221485\n",
            ">> Epoch 64 finished \tANN training loss 0.287643\n",
            ">> Epoch 65 finished \tANN training loss 0.261605\n",
            ">> Epoch 66 finished \tANN training loss 0.232030\n",
            ">> Epoch 67 finished \tANN training loss 0.212772\n",
            ">> Epoch 68 finished \tANN training loss 0.341266\n",
            ">> Epoch 69 finished \tANN training loss 0.228987\n",
            ">> Epoch 70 finished \tANN training loss 0.247523\n",
            ">> Epoch 71 finished \tANN training loss 0.185374\n",
            ">> Epoch 72 finished \tANN training loss 0.239396\n",
            ">> Epoch 73 finished \tANN training loss 0.171875\n",
            ">> Epoch 74 finished \tANN training loss 0.168191\n",
            ">> Epoch 75 finished \tANN training loss 0.168862\n",
            ">> Epoch 76 finished \tANN training loss 0.319793\n",
            ">> Epoch 77 finished \tANN training loss 0.205173\n",
            ">> Epoch 78 finished \tANN training loss 0.174847\n",
            ">> Epoch 79 finished \tANN training loss 0.159940\n",
            ">> Epoch 80 finished \tANN training loss 0.169374\n",
            ">> Epoch 81 finished \tANN training loss 0.161327\n",
            ">> Epoch 82 finished \tANN training loss 0.162334\n",
            ">> Epoch 83 finished \tANN training loss 0.354639\n",
            ">> Epoch 84 finished \tANN training loss 0.189050\n",
            ">> Epoch 85 finished \tANN training loss 0.203366\n",
            ">> Epoch 86 finished \tANN training loss 0.143702\n",
            ">> Epoch 87 finished \tANN training loss 0.228449\n",
            ">> Epoch 88 finished \tANN training loss 0.123880\n",
            ">> Epoch 89 finished \tANN training loss 0.156070\n",
            ">> Epoch 90 finished \tANN training loss 0.139956\n",
            ">> Epoch 91 finished \tANN training loss 0.231481\n",
            ">> Epoch 92 finished \tANN training loss 0.118180\n",
            ">> Epoch 93 finished \tANN training loss 0.113211\n",
            ">> Epoch 94 finished \tANN training loss 0.141887\n",
            ">> Epoch 95 finished \tANN training loss 0.177936\n",
            ">> Epoch 96 finished \tANN training loss 0.131760\n",
            ">> Epoch 97 finished \tANN training loss 0.125809\n",
            ">> Epoch 98 finished \tANN training loss 0.121686\n",
            ">> Epoch 99 finished \tANN training loss 0.165044\n",
            "[END] Fine tuning step\n",
            "\n",
            "Accuracy: 0.931373\n",
            "Confusion Matrix:\n",
            " [[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 11  0  0  0  0  0  0  0  0  1  0  0  0  0  0]\n",
            " [ 0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0 13]]\n"
          ]
        }
      ],
      "source": [
        "#case4\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(3529)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "\n",
        "dataset = pd.read_csv(\"Instruments.csv\")\n",
        "dataset = dataset.drop([\"File Name\"], axis=1)\n",
        "\n",
        "le = LabelEncoder()\n",
        "dataset['Instrument'] = le.fit_transform(dataset['Instrument'])\n",
        "\n",
        "X = np.array(dataset.drop([\"Instrument\"], axis=1))\n",
        "Y = np.array(dataset.Instrument.values)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[256, 256],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.4,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='sigmoid',\n",
        "                                         dropout_p=0.05)\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print('\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcc6b7f1",
      "metadata": {
        "id": "fcc6b7f1",
        "outputId": "f7391dc0-bc2e-4909-de59-862131b575e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 41.452019\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 40.543458\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 40.711748\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 41.021558\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 41.274169\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 41.495661\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 41.789053\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 41.998737\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 42.236481\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 42.178893\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 14.061078\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 10.807890\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 9.859759\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 9.207584\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 8.653982\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 8.070736\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 7.613231\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 7.054420\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 6.930345\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 6.447775\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss 3.099351\n",
            ">> Epoch 1 finished \tANN training loss 3.690585\n",
            ">> Epoch 2 finished \tANN training loss 1.846033\n",
            ">> Epoch 3 finished \tANN training loss 1.780526\n",
            ">> Epoch 4 finished \tANN training loss 1.993870\n",
            ">> Epoch 5 finished \tANN training loss 1.328447\n",
            ">> Epoch 6 finished \tANN training loss 1.570774\n",
            ">> Epoch 7 finished \tANN training loss 1.445312\n",
            ">> Epoch 8 finished \tANN training loss 1.099473\n",
            ">> Epoch 9 finished \tANN training loss 0.944150\n",
            ">> Epoch 10 finished \tANN training loss 1.163033\n",
            ">> Epoch 11 finished \tANN training loss 0.915219\n",
            ">> Epoch 12 finished \tANN training loss 1.020712\n",
            ">> Epoch 13 finished \tANN training loss 0.825129\n",
            ">> Epoch 14 finished \tANN training loss 1.211958\n",
            ">> Epoch 15 finished \tANN training loss 0.939748\n",
            ">> Epoch 16 finished \tANN training loss 0.948906\n",
            ">> Epoch 17 finished \tANN training loss 1.122801\n",
            ">> Epoch 18 finished \tANN training loss 1.027700\n",
            ">> Epoch 19 finished \tANN training loss 0.868018\n",
            ">> Epoch 20 finished \tANN training loss 0.639140\n",
            ">> Epoch 21 finished \tANN training loss 0.752026\n",
            ">> Epoch 22 finished \tANN training loss 0.920182\n",
            ">> Epoch 23 finished \tANN training loss 0.917732\n",
            ">> Epoch 24 finished \tANN training loss 0.755384\n",
            ">> Epoch 25 finished \tANN training loss 1.310156\n",
            ">> Epoch 26 finished \tANN training loss 0.614711\n",
            ">> Epoch 27 finished \tANN training loss 0.537003\n",
            ">> Epoch 28 finished \tANN training loss 0.515101\n",
            ">> Epoch 29 finished \tANN training loss 0.602237\n",
            ">> Epoch 30 finished \tANN training loss 0.611064\n",
            ">> Epoch 31 finished \tANN training loss 1.283455\n",
            ">> Epoch 32 finished \tANN training loss 1.082329\n",
            ">> Epoch 33 finished \tANN training loss 0.446334\n",
            ">> Epoch 34 finished \tANN training loss 0.477346\n",
            ">> Epoch 35 finished \tANN training loss 0.863169\n",
            ">> Epoch 36 finished \tANN training loss 0.427697\n",
            ">> Epoch 37 finished \tANN training loss 0.509130\n",
            ">> Epoch 38 finished \tANN training loss 0.493523\n",
            ">> Epoch 39 finished \tANN training loss 0.443775\n",
            ">> Epoch 40 finished \tANN training loss 0.432427\n",
            ">> Epoch 41 finished \tANN training loss 0.499896\n",
            ">> Epoch 42 finished \tANN training loss 0.456430\n",
            ">> Epoch 43 finished \tANN training loss 0.612598\n",
            ">> Epoch 44 finished \tANN training loss 0.378792\n",
            ">> Epoch 45 finished \tANN training loss 0.443362\n",
            ">> Epoch 46 finished \tANN training loss 0.432399\n",
            ">> Epoch 47 finished \tANN training loss 0.317934\n",
            ">> Epoch 48 finished \tANN training loss 0.302224\n",
            ">> Epoch 49 finished \tANN training loss 0.474888\n",
            ">> Epoch 50 finished \tANN training loss 0.457301\n",
            ">> Epoch 51 finished \tANN training loss 0.365441\n",
            ">> Epoch 52 finished \tANN training loss 0.490203\n",
            ">> Epoch 53 finished \tANN training loss 0.379194\n",
            ">> Epoch 54 finished \tANN training loss 0.282750\n",
            ">> Epoch 55 finished \tANN training loss 0.321877\n",
            ">> Epoch 56 finished \tANN training loss 0.385713\n",
            ">> Epoch 57 finished \tANN training loss 0.254959\n",
            ">> Epoch 58 finished \tANN training loss 0.310375\n",
            ">> Epoch 59 finished \tANN training loss 0.284413\n",
            ">> Epoch 60 finished \tANN training loss 0.293341\n",
            ">> Epoch 61 finished \tANN training loss 0.292962\n",
            ">> Epoch 62 finished \tANN training loss 0.238246\n",
            ">> Epoch 63 finished \tANN training loss 0.258658\n",
            ">> Epoch 64 finished \tANN training loss 0.283514\n",
            ">> Epoch 65 finished \tANN training loss 0.284998\n",
            ">> Epoch 66 finished \tANN training loss 0.289878\n",
            ">> Epoch 67 finished \tANN training loss 0.262780\n",
            ">> Epoch 68 finished \tANN training loss 0.232620\n",
            ">> Epoch 69 finished \tANN training loss 0.239553\n",
            ">> Epoch 70 finished \tANN training loss 0.270340\n",
            ">> Epoch 71 finished \tANN training loss 0.260992\n",
            ">> Epoch 72 finished \tANN training loss 0.194435\n",
            ">> Epoch 73 finished \tANN training loss 0.212557\n",
            ">> Epoch 74 finished \tANN training loss 0.242026\n",
            ">> Epoch 75 finished \tANN training loss 0.260550\n",
            ">> Epoch 76 finished \tANN training loss 0.334537\n",
            ">> Epoch 77 finished \tANN training loss 0.614288\n",
            ">> Epoch 78 finished \tANN training loss 0.166397\n",
            ">> Epoch 79 finished \tANN training loss 0.179294\n",
            ">> Epoch 80 finished \tANN training loss 0.202732\n",
            ">> Epoch 81 finished \tANN training loss 0.167124\n",
            ">> Epoch 82 finished \tANN training loss 0.145069\n",
            ">> Epoch 83 finished \tANN training loss 0.178274\n",
            ">> Epoch 84 finished \tANN training loss 0.219602\n",
            ">> Epoch 85 finished \tANN training loss 0.208531\n",
            ">> Epoch 86 finished \tANN training loss 0.143639\n",
            ">> Epoch 87 finished \tANN training loss 0.204151\n",
            ">> Epoch 88 finished \tANN training loss 0.152926\n",
            ">> Epoch 89 finished \tANN training loss 0.178770\n",
            ">> Epoch 90 finished \tANN training loss 0.191168\n",
            ">> Epoch 91 finished \tANN training loss 0.197651\n",
            ">> Epoch 92 finished \tANN training loss 0.146057\n",
            ">> Epoch 93 finished \tANN training loss 0.131446\n",
            ">> Epoch 94 finished \tANN training loss 0.146481\n",
            ">> Epoch 95 finished \tANN training loss 0.159577\n",
            ">> Epoch 96 finished \tANN training loss 0.127134\n",
            ">> Epoch 97 finished \tANN training loss 0.153763\n",
            ">> Epoch 98 finished \tANN training loss 0.131997\n",
            ">> Epoch 99 finished \tANN training loss 0.161735\n",
            "[END] Fine tuning step\n",
            "\n",
            "Accuracy: 0.926471\n",
            "Confusion Matrix:\n",
            " [[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0 14  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  1 12]]\n"
          ]
        }
      ],
      "source": [
        "#case5\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(3529)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "\n",
        "dataset = pd.read_csv(\"Instruments.csv\")\n",
        "dataset = dataset.drop([\"File Name\"], axis=1)\n",
        "\n",
        "le = LabelEncoder()\n",
        "dataset['Instrument'] = le.fit_transform(dataset['Instrument'])\n",
        "\n",
        "X = np.array(dataset.drop([\"Instrument\"], axis=1))\n",
        "Y = np.array(dataset.Instrument.values)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[256, 256],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.4,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='sigmoid',\n",
        "                                         dropout_p=0.1)\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print('\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39db751a",
      "metadata": {
        "scrolled": false,
        "id": "39db751a",
        "outputId": "c5cdd9ad-6da0-4f03-af5c-83b2a9112c5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 41.850058\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 40.894614\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 40.964123\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 41.160024\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 41.381316\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 41.600540\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 41.795998\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 42.015733\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 42.387931\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 42.106841\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 14.815408\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 11.054120\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 10.096250\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 9.336926\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 8.701862\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 8.046473\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 7.714260\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 7.135638\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 6.876895\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 6.518500\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss 2.718808\n",
            ">> Epoch 1 finished \tANN training loss 3.416688\n",
            ">> Epoch 2 finished \tANN training loss 1.814120\n",
            ">> Epoch 3 finished \tANN training loss 1.778116\n",
            ">> Epoch 4 finished \tANN training loss 1.885764\n",
            ">> Epoch 5 finished \tANN training loss 1.402628\n",
            ">> Epoch 6 finished \tANN training loss 1.176439\n",
            ">> Epoch 7 finished \tANN training loss 1.260576\n",
            ">> Epoch 8 finished \tANN training loss 1.306911\n",
            ">> Epoch 9 finished \tANN training loss 1.187582\n",
            ">> Epoch 10 finished \tANN training loss 0.969498\n",
            ">> Epoch 11 finished \tANN training loss 0.976272\n",
            ">> Epoch 12 finished \tANN training loss 1.066424\n",
            ">> Epoch 13 finished \tANN training loss 0.802644\n",
            ">> Epoch 14 finished \tANN training loss 1.021625\n",
            ">> Epoch 15 finished \tANN training loss 1.114406\n",
            ">> Epoch 16 finished \tANN training loss 1.012872\n",
            ">> Epoch 17 finished \tANN training loss 1.134081\n",
            ">> Epoch 18 finished \tANN training loss 0.989781\n",
            ">> Epoch 19 finished \tANN training loss 0.777639\n",
            ">> Epoch 20 finished \tANN training loss 0.725350\n",
            ">> Epoch 21 finished \tANN training loss 0.752409\n",
            ">> Epoch 22 finished \tANN training loss 0.768745\n",
            ">> Epoch 23 finished \tANN training loss 0.967344\n",
            ">> Epoch 24 finished \tANN training loss 0.754432\n",
            ">> Epoch 25 finished \tANN training loss 0.860515\n",
            ">> Epoch 26 finished \tANN training loss 0.645970\n",
            ">> Epoch 27 finished \tANN training loss 0.638390\n",
            ">> Epoch 28 finished \tANN training loss 0.506377\n",
            ">> Epoch 29 finished \tANN training loss 0.621008\n",
            ">> Epoch 30 finished \tANN training loss 0.624500\n",
            ">> Epoch 31 finished \tANN training loss 1.045910\n",
            ">> Epoch 32 finished \tANN training loss 0.916337\n",
            ">> Epoch 33 finished \tANN training loss 0.512938\n",
            ">> Epoch 34 finished \tANN training loss 0.589099\n",
            ">> Epoch 35 finished \tANN training loss 0.860165\n",
            ">> Epoch 36 finished \tANN training loss 0.592429\n",
            ">> Epoch 37 finished \tANN training loss 0.591650\n",
            ">> Epoch 38 finished \tANN training loss 0.455230\n",
            ">> Epoch 39 finished \tANN training loss 0.557336\n",
            ">> Epoch 40 finished \tANN training loss 0.518949\n",
            ">> Epoch 41 finished \tANN training loss 0.581727\n",
            ">> Epoch 42 finished \tANN training loss 0.480343\n",
            ">> Epoch 43 finished \tANN training loss 0.427032\n",
            ">> Epoch 44 finished \tANN training loss 0.471221\n",
            ">> Epoch 45 finished \tANN training loss 0.456733\n",
            ">> Epoch 46 finished \tANN training loss 0.506937\n",
            ">> Epoch 47 finished \tANN training loss 0.414737\n",
            ">> Epoch 48 finished \tANN training loss 0.383229\n",
            ">> Epoch 49 finished \tANN training loss 0.648670\n",
            ">> Epoch 50 finished \tANN training loss 0.515359\n",
            ">> Epoch 51 finished \tANN training loss 0.407835\n",
            ">> Epoch 52 finished \tANN training loss 0.483763\n",
            ">> Epoch 53 finished \tANN training loss 0.382627\n",
            ">> Epoch 54 finished \tANN training loss 0.390435\n",
            ">> Epoch 55 finished \tANN training loss 0.400153\n",
            ">> Epoch 56 finished \tANN training loss 0.504246\n",
            ">> Epoch 57 finished \tANN training loss 0.384212\n",
            ">> Epoch 58 finished \tANN training loss 0.375902\n",
            ">> Epoch 59 finished \tANN training loss 0.404311\n",
            ">> Epoch 60 finished \tANN training loss 0.445458\n",
            ">> Epoch 61 finished \tANN training loss 0.334489\n",
            ">> Epoch 62 finished \tANN training loss 0.361197\n",
            ">> Epoch 63 finished \tANN training loss 0.329897\n",
            ">> Epoch 64 finished \tANN training loss 0.290024\n",
            ">> Epoch 65 finished \tANN training loss 0.326399\n",
            ">> Epoch 66 finished \tANN training loss 0.326028\n",
            ">> Epoch 67 finished \tANN training loss 0.407774\n",
            ">> Epoch 68 finished \tANN training loss 0.346832\n",
            ">> Epoch 69 finished \tANN training loss 0.352717\n",
            ">> Epoch 70 finished \tANN training loss 0.273628\n",
            ">> Epoch 71 finished \tANN training loss 0.356377\n",
            ">> Epoch 72 finished \tANN training loss 0.315419\n",
            ">> Epoch 73 finished \tANN training loss 0.257262\n",
            ">> Epoch 74 finished \tANN training loss 0.297363\n",
            ">> Epoch 75 finished \tANN training loss 0.255015\n",
            ">> Epoch 76 finished \tANN training loss 0.373465\n",
            ">> Epoch 77 finished \tANN training loss 0.273223\n",
            ">> Epoch 78 finished \tANN training loss 0.242477\n",
            ">> Epoch 79 finished \tANN training loss 0.276181\n",
            ">> Epoch 80 finished \tANN training loss 0.260728\n",
            ">> Epoch 81 finished \tANN training loss 0.253995\n",
            ">> Epoch 82 finished \tANN training loss 0.215218\n",
            ">> Epoch 83 finished \tANN training loss 0.276128\n",
            ">> Epoch 84 finished \tANN training loss 0.287112\n",
            ">> Epoch 85 finished \tANN training loss 0.282366\n",
            ">> Epoch 86 finished \tANN training loss 0.260891\n",
            ">> Epoch 87 finished \tANN training loss 0.242337\n",
            ">> Epoch 88 finished \tANN training loss 0.211894\n",
            ">> Epoch 89 finished \tANN training loss 0.214325\n",
            ">> Epoch 90 finished \tANN training loss 0.234565\n",
            ">> Epoch 91 finished \tANN training loss 0.236237\n",
            ">> Epoch 92 finished \tANN training loss 0.205068\n",
            ">> Epoch 93 finished \tANN training loss 0.201132\n",
            ">> Epoch 94 finished \tANN training loss 0.186718\n",
            ">> Epoch 95 finished \tANN training loss 0.204233\n",
            ">> Epoch 96 finished \tANN training loss 0.221619\n",
            ">> Epoch 97 finished \tANN training loss 0.265261\n",
            ">> Epoch 98 finished \tANN training loss 0.188180\n",
            ">> Epoch 99 finished \tANN training loss 0.242758\n",
            "[END] Fine tuning step\n",
            "\n",
            "Accuracy: 0.872549\n",
            "Confusion Matrix:\n",
            " [[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  5  0  6  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0]\n",
            " [ 0  0  1  0  1  0  0  0  0  0 13  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  2  0  0  0  0  0  0  0 14  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0]\n",
            " [ 0  0  1  0  0  0  0  0  1  0  0  0  0  0  1  3  9]]\n"
          ]
        }
      ],
      "source": [
        "#case6\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(3529)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "\n",
        "dataset = pd.read_csv(\"Instruments.csv\")\n",
        "dataset = dataset.drop([\"File Name\"], axis=1)\n",
        "\n",
        "le = LabelEncoder()\n",
        "dataset['Instrument'] = le.fit_transform(dataset['Instrument'])\n",
        "\n",
        "X = np.array(dataset.drop([\"Instrument\"], axis=1))\n",
        "Y = np.array(dataset.Instrument.values)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[256, 256],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.4,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='sigmoid',\n",
        "                                         dropout_p=0.2)\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print('\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eefb2ecb",
      "metadata": {
        "id": "eefb2ecb",
        "outputId": "98f1905c-5d86-4ce4-d443-189a2e0e38a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 43.611068\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 42.323009\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 42.124878\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 42.228901\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 42.515722\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 42.770853\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 42.997237\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 43.172563\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 43.458511\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 43.307241\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 9.489080\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 6.303519\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 5.026020\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 4.575114\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 4.419034\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 4.197204\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 4.079415\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 3.926174\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 3.837740\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 3.688907\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 3.424402\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 1.400390\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 0.868024\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.716623\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.662347\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.653877\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.631490\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.619303\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.589857\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.523940\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 3.008495\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 1.183653\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 0.472936\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.303096\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.269574\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.247869\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.223870\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.204703\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.206227\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.192435\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss 2.153566\n",
            ">> Epoch 1 finished \tANN training loss 2.086350\n",
            ">> Epoch 2 finished \tANN training loss 2.101676\n",
            ">> Epoch 3 finished \tANN training loss 2.073774\n",
            ">> Epoch 4 finished \tANN training loss 1.979826\n",
            ">> Epoch 5 finished \tANN training loss 1.880534\n",
            ">> Epoch 6 finished \tANN training loss 2.024677\n",
            ">> Epoch 7 finished \tANN training loss 1.797245\n",
            ">> Epoch 8 finished \tANN training loss 1.709345\n",
            ">> Epoch 9 finished \tANN training loss 1.801885\n",
            ">> Epoch 10 finished \tANN training loss 1.719839\n",
            ">> Epoch 11 finished \tANN training loss 1.599324\n",
            ">> Epoch 12 finished \tANN training loss 1.614488\n",
            ">> Epoch 13 finished \tANN training loss 1.648429\n",
            ">> Epoch 14 finished \tANN training loss 1.585097\n",
            ">> Epoch 15 finished \tANN training loss 1.556749\n",
            ">> Epoch 16 finished \tANN training loss 1.547412\n",
            ">> Epoch 17 finished \tANN training loss 1.534549\n",
            ">> Epoch 18 finished \tANN training loss 1.480174\n",
            ">> Epoch 19 finished \tANN training loss 1.552689\n",
            ">> Epoch 20 finished \tANN training loss 1.505747\n",
            ">> Epoch 21 finished \tANN training loss 1.526027\n",
            ">> Epoch 22 finished \tANN training loss 1.435349\n",
            ">> Epoch 23 finished \tANN training loss 1.401416\n",
            ">> Epoch 24 finished \tANN training loss 1.403844\n",
            ">> Epoch 25 finished \tANN training loss 1.467097\n",
            ">> Epoch 26 finished \tANN training loss 1.397644\n",
            ">> Epoch 27 finished \tANN training loss 1.301118\n",
            ">> Epoch 28 finished \tANN training loss 1.372970\n",
            ">> Epoch 29 finished \tANN training loss 1.275185\n",
            ">> Epoch 30 finished \tANN training loss 1.292008\n",
            ">> Epoch 31 finished \tANN training loss 1.339373\n",
            ">> Epoch 32 finished \tANN training loss 1.231508\n",
            ">> Epoch 33 finished \tANN training loss 1.178891\n",
            ">> Epoch 34 finished \tANN training loss 1.151788\n",
            ">> Epoch 35 finished \tANN training loss 1.226502\n",
            ">> Epoch 36 finished \tANN training loss 1.139428\n",
            ">> Epoch 37 finished \tANN training loss 1.346881\n",
            ">> Epoch 38 finished \tANN training loss 1.055764\n",
            ">> Epoch 39 finished \tANN training loss 1.112608\n",
            ">> Epoch 40 finished \tANN training loss 1.116235\n",
            ">> Epoch 41 finished \tANN training loss 1.027043\n",
            ">> Epoch 42 finished \tANN training loss 1.031240\n",
            ">> Epoch 43 finished \tANN training loss 1.008655\n",
            ">> Epoch 44 finished \tANN training loss 1.042904\n",
            ">> Epoch 45 finished \tANN training loss 0.982141\n",
            ">> Epoch 46 finished \tANN training loss 0.954353\n",
            ">> Epoch 47 finished \tANN training loss 1.037781\n",
            ">> Epoch 48 finished \tANN training loss 0.953754\n",
            ">> Epoch 49 finished \tANN training loss 0.947172\n",
            ">> Epoch 50 finished \tANN training loss 0.929894\n",
            ">> Epoch 51 finished \tANN training loss 1.004077\n",
            ">> Epoch 52 finished \tANN training loss 0.848558\n",
            ">> Epoch 53 finished \tANN training loss 0.849199\n",
            ">> Epoch 54 finished \tANN training loss 0.855254\n",
            ">> Epoch 55 finished \tANN training loss 0.957421\n",
            ">> Epoch 56 finished \tANN training loss 0.786234\n",
            ">> Epoch 57 finished \tANN training loss 0.935120\n",
            ">> Epoch 58 finished \tANN training loss 0.969913\n",
            ">> Epoch 59 finished \tANN training loss 0.824870\n",
            ">> Epoch 60 finished \tANN training loss 0.860923\n",
            ">> Epoch 61 finished \tANN training loss 0.798085\n",
            ">> Epoch 62 finished \tANN training loss 0.722395\n",
            ">> Epoch 63 finished \tANN training loss 0.687953\n",
            ">> Epoch 64 finished \tANN training loss 0.759430\n",
            ">> Epoch 65 finished \tANN training loss 0.700532\n",
            ">> Epoch 66 finished \tANN training loss 0.688448\n",
            ">> Epoch 67 finished \tANN training loss 0.768305\n",
            ">> Epoch 68 finished \tANN training loss 0.655071\n",
            ">> Epoch 69 finished \tANN training loss 0.704207\n",
            ">> Epoch 70 finished \tANN training loss 0.663004\n",
            ">> Epoch 71 finished \tANN training loss 0.600730\n",
            ">> Epoch 72 finished \tANN training loss 0.656497\n",
            ">> Epoch 73 finished \tANN training loss 0.683468\n",
            ">> Epoch 74 finished \tANN training loss 0.586385\n",
            ">> Epoch 75 finished \tANN training loss 0.581089\n",
            ">> Epoch 76 finished \tANN training loss 0.685384\n",
            ">> Epoch 77 finished \tANN training loss 0.589066\n",
            ">> Epoch 78 finished \tANN training loss 0.619617\n",
            ">> Epoch 79 finished \tANN training loss 0.665656\n",
            ">> Epoch 80 finished \tANN training loss 0.551548\n",
            ">> Epoch 81 finished \tANN training loss 0.682065\n",
            ">> Epoch 82 finished \tANN training loss 0.564787\n",
            ">> Epoch 83 finished \tANN training loss 0.716488\n",
            ">> Epoch 84 finished \tANN training loss 0.550645\n",
            ">> Epoch 85 finished \tANN training loss 0.571785\n",
            ">> Epoch 86 finished \tANN training loss 0.583134\n",
            ">> Epoch 87 finished \tANN training loss 0.549609\n",
            ">> Epoch 88 finished \tANN training loss 0.629348\n",
            ">> Epoch 89 finished \tANN training loss 0.481051\n",
            ">> Epoch 90 finished \tANN training loss 0.507449\n",
            ">> Epoch 91 finished \tANN training loss 0.484555\n",
            ">> Epoch 92 finished \tANN training loss 0.526343\n",
            ">> Epoch 93 finished \tANN training loss 0.696431\n",
            ">> Epoch 94 finished \tANN training loss 0.688071\n",
            ">> Epoch 95 finished \tANN training loss 0.697145\n",
            ">> Epoch 96 finished \tANN training loss 0.672433\n",
            ">> Epoch 97 finished \tANN training loss 0.628760\n",
            ">> Epoch 98 finished \tANN training loss 0.511595\n",
            ">> Epoch 99 finished \tANN training loss 0.402390\n",
            "[END] Fine tuning step\n",
            "\n",
            "Accuracy: 0.852941\n",
            "Confusion Matrix:\n",
            " [[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  9  0  0  0  0  0  0  0  3  0  0  0  0  0  0]\n",
            " [ 0  0  0 10  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  6  0  2  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  0 15  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  1  0  0  0  0  5  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  1  0  0  0  0  0 14  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  3]\n",
            " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  2  0  8  1]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  1 12]]\n"
          ]
        }
      ],
      "source": [
        "#case 7\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(3529)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "\n",
        "\n",
        "dataset = pd.read_csv(\"Instruments.csv\")\n",
        "dataset = dataset.drop([\"File Name\"], axis=1)\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "dataset['Instrument'] = le.fit_transform(dataset['Instrument'])\n",
        "\n",
        "X = np.array(dataset.drop([\"Instrument\"], axis=1))\n",
        "Y = np.array(dataset.Instrument.values)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[128, 128, 128, 128],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.4,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='sigmoid',\n",
        "                                         dropout_p=0.05)\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print('\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe063e62",
      "metadata": {
        "id": "fe063e62",
        "outputId": "144aa44f-ae65-4ee5-bf4f-c38239379421"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 43.862700\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 43.131203\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 43.034387\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 43.150786\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 43.268527\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 43.463622\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 43.633679\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 43.762163\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 44.120498\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 44.008004\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 11.074246\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 7.542301\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 5.969889\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 5.339882\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 5.073346\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 4.748718\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 4.537777\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 4.353485\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 4.203320\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 4.109626\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 4.082773\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 1.579649\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 1.004919\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.883139\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.805344\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.800753\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.743595\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.697562\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.660530\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.614470\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 3.436915\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 1.213127\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 0.517840\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.337148\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.280519\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.263852\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.230781\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.235931\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.197512\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.207421\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss 2.236196\n",
            ">> Epoch 1 finished \tANN training loss 2.154101\n",
            ">> Epoch 2 finished \tANN training loss 2.241579\n",
            ">> Epoch 3 finished \tANN training loss 2.083358\n",
            ">> Epoch 4 finished \tANN training loss 2.016831\n",
            ">> Epoch 5 finished \tANN training loss 1.860466\n",
            ">> Epoch 6 finished \tANN training loss 2.092218\n",
            ">> Epoch 7 finished \tANN training loss 1.887535\n",
            ">> Epoch 8 finished \tANN training loss 1.762124\n",
            ">> Epoch 9 finished \tANN training loss 1.796763\n",
            ">> Epoch 10 finished \tANN training loss 1.735878\n",
            ">> Epoch 11 finished \tANN training loss 1.643505\n",
            ">> Epoch 12 finished \tANN training loss 1.634183\n",
            ">> Epoch 13 finished \tANN training loss 1.747173\n",
            ">> Epoch 14 finished \tANN training loss 1.578380\n",
            ">> Epoch 15 finished \tANN training loss 1.553794\n",
            ">> Epoch 16 finished \tANN training loss 1.546279\n",
            ">> Epoch 17 finished \tANN training loss 1.521776\n",
            ">> Epoch 18 finished \tANN training loss 1.517237\n",
            ">> Epoch 19 finished \tANN training loss 1.560154\n",
            ">> Epoch 20 finished \tANN training loss 1.457675\n",
            ">> Epoch 21 finished \tANN training loss 1.450898\n",
            ">> Epoch 22 finished \tANN training loss 1.426255\n",
            ">> Epoch 23 finished \tANN training loss 1.402175\n",
            ">> Epoch 24 finished \tANN training loss 1.402005\n",
            ">> Epoch 25 finished \tANN training loss 1.506710\n",
            ">> Epoch 26 finished \tANN training loss 1.372117\n",
            ">> Epoch 27 finished \tANN training loss 1.344714\n",
            ">> Epoch 28 finished \tANN training loss 1.420532\n",
            ">> Epoch 29 finished \tANN training loss 1.331015\n",
            ">> Epoch 30 finished \tANN training loss 1.245345\n",
            ">> Epoch 31 finished \tANN training loss 1.210212\n",
            ">> Epoch 32 finished \tANN training loss 1.238708\n",
            ">> Epoch 33 finished \tANN training loss 1.221147\n",
            ">> Epoch 34 finished \tANN training loss 1.174080\n",
            ">> Epoch 35 finished \tANN training loss 1.265576\n",
            ">> Epoch 36 finished \tANN training loss 1.119487\n",
            ">> Epoch 37 finished \tANN training loss 1.125924\n",
            ">> Epoch 38 finished \tANN training loss 1.067990\n",
            ">> Epoch 39 finished \tANN training loss 1.096529\n",
            ">> Epoch 40 finished \tANN training loss 1.093302\n",
            ">> Epoch 41 finished \tANN training loss 0.997662\n",
            ">> Epoch 42 finished \tANN training loss 0.983302\n",
            ">> Epoch 43 finished \tANN training loss 1.074824\n",
            ">> Epoch 44 finished \tANN training loss 1.075821\n",
            ">> Epoch 45 finished \tANN training loss 0.908324\n",
            ">> Epoch 46 finished \tANN training loss 0.883497\n",
            ">> Epoch 47 finished \tANN training loss 0.919771\n",
            ">> Epoch 48 finished \tANN training loss 1.043951\n",
            ">> Epoch 49 finished \tANN training loss 0.892177\n",
            ">> Epoch 50 finished \tANN training loss 0.837381\n",
            ">> Epoch 51 finished \tANN training loss 0.832067\n",
            ">> Epoch 52 finished \tANN training loss 0.830100\n",
            ">> Epoch 53 finished \tANN training loss 0.807840\n",
            ">> Epoch 54 finished \tANN training loss 0.802779\n",
            ">> Epoch 55 finished \tANN training loss 0.745554\n",
            ">> Epoch 56 finished \tANN training loss 0.906654\n",
            ">> Epoch 57 finished \tANN training loss 0.842373\n",
            ">> Epoch 58 finished \tANN training loss 0.805926\n",
            ">> Epoch 59 finished \tANN training loss 0.855421\n",
            ">> Epoch 60 finished \tANN training loss 0.779791\n",
            ">> Epoch 61 finished \tANN training loss 0.769894\n",
            ">> Epoch 62 finished \tANN training loss 0.826937\n",
            ">> Epoch 63 finished \tANN training loss 0.729880\n",
            ">> Epoch 64 finished \tANN training loss 0.687411\n",
            ">> Epoch 65 finished \tANN training loss 0.702664\n",
            ">> Epoch 66 finished \tANN training loss 0.717851\n",
            ">> Epoch 67 finished \tANN training loss 0.728867\n",
            ">> Epoch 68 finished \tANN training loss 0.713585\n",
            ">> Epoch 69 finished \tANN training loss 0.697073\n",
            ">> Epoch 70 finished \tANN training loss 0.717017\n",
            ">> Epoch 71 finished \tANN training loss 0.660610\n",
            ">> Epoch 72 finished \tANN training loss 0.662168\n",
            ">> Epoch 73 finished \tANN training loss 0.659880\n",
            ">> Epoch 74 finished \tANN training loss 0.642302\n",
            ">> Epoch 75 finished \tANN training loss 0.632477\n",
            ">> Epoch 76 finished \tANN training loss 0.637926\n",
            ">> Epoch 77 finished \tANN training loss 0.706719\n",
            ">> Epoch 78 finished \tANN training loss 0.643955\n",
            ">> Epoch 79 finished \tANN training loss 0.604086\n",
            ">> Epoch 80 finished \tANN training loss 0.698737\n",
            ">> Epoch 81 finished \tANN training loss 0.647504\n",
            ">> Epoch 82 finished \tANN training loss 0.617290\n",
            ">> Epoch 83 finished \tANN training loss 0.609476\n",
            ">> Epoch 84 finished \tANN training loss 0.602303\n",
            ">> Epoch 85 finished \tANN training loss 0.622460\n",
            ">> Epoch 86 finished \tANN training loss 0.611600\n",
            ">> Epoch 87 finished \tANN training loss 0.584281\n",
            ">> Epoch 88 finished \tANN training loss 0.607825\n",
            ">> Epoch 89 finished \tANN training loss 0.603049\n",
            ">> Epoch 90 finished \tANN training loss 0.639664\n",
            ">> Epoch 91 finished \tANN training loss 0.618348\n",
            ">> Epoch 92 finished \tANN training loss 0.580980\n",
            ">> Epoch 93 finished \tANN training loss 0.616672\n",
            ">> Epoch 94 finished \tANN training loss 0.580682\n",
            ">> Epoch 95 finished \tANN training loss 0.572026\n",
            ">> Epoch 96 finished \tANN training loss 0.559155\n",
            ">> Epoch 97 finished \tANN training loss 0.568003\n",
            ">> Epoch 98 finished \tANN training loss 0.541280\n",
            ">> Epoch 99 finished \tANN training loss 0.580273\n",
            "[END] Fine tuning step\n",
            "\n",
            "Accuracy: 0.710784\n",
            "Confusion Matrix:\n",
            " [[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0]\n",
            " [ 0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  6  0  5  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0]\n",
            " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  7  0  4]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  8  1]\n",
            " [ 0  0  0  0  0  0  0  2  1  0  0  1  0  0  0  2  9]]\n"
          ]
        }
      ],
      "source": [
        "#case 8\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(3529)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "\n",
        "\n",
        "dataset = pd.read_csv(\"Instruments.csv\")\n",
        "dataset = dataset.drop([\"File Name\"], axis=1)\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "dataset['Instrument'] = le.fit_transform(dataset['Instrument'])\n",
        "\n",
        "X = np.array(dataset.drop([\"Instrument\"], axis=1))\n",
        "Y = np.array(dataset.Instrument.values)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[128, 128, 128, 128],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.4,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='sigmoid',\n",
        "                                         dropout_p=0.1)\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print('\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4effc468",
      "metadata": {
        "id": "4effc468",
        "outputId": "c31b6f7b-1f7e-4bda-f64d-dd94bea14912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 43.231257\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 42.375992\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 42.243234\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 42.214945\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 42.350674\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 42.420852\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 42.563558\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 42.631410\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 42.861455\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 42.754961\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 9.733202\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 6.367573\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 5.268157\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 4.822360\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 4.627028\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 4.419239\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 4.263068\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 4.109338\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 3.995229\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 3.835503\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 3.560134\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 1.531209\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 0.942849\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.857359\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.817596\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.791272\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.732284\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.695379\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.723669\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.674755\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 2.774211\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 1.092773\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 0.459111\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.312057\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.263150\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.256782\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.229957\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.204971\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.212785\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.183680\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss 2.161781\n",
            ">> Epoch 1 finished \tANN training loss 2.162324\n",
            ">> Epoch 2 finished \tANN training loss 2.231463\n",
            ">> Epoch 3 finished \tANN training loss 2.037632\n",
            ">> Epoch 4 finished \tANN training loss 2.005377\n",
            ">> Epoch 5 finished \tANN training loss 1.926284\n",
            ">> Epoch 6 finished \tANN training loss 2.027987\n",
            ">> Epoch 7 finished \tANN training loss 1.953428\n",
            ">> Epoch 8 finished \tANN training loss 1.832274\n",
            ">> Epoch 9 finished \tANN training loss 1.863648\n",
            ">> Epoch 10 finished \tANN training loss 1.835893\n",
            ">> Epoch 11 finished \tANN training loss 1.673477\n",
            ">> Epoch 12 finished \tANN training loss 1.691658\n",
            ">> Epoch 13 finished \tANN training loss 1.692844\n",
            ">> Epoch 14 finished \tANN training loss 1.663815\n",
            ">> Epoch 15 finished \tANN training loss 1.615688\n",
            ">> Epoch 16 finished \tANN training loss 1.618857\n",
            ">> Epoch 17 finished \tANN training loss 1.618945\n",
            ">> Epoch 18 finished \tANN training loss 1.594308\n",
            ">> Epoch 19 finished \tANN training loss 1.616004\n",
            ">> Epoch 20 finished \tANN training loss 1.566871\n",
            ">> Epoch 21 finished \tANN training loss 1.586625\n",
            ">> Epoch 22 finished \tANN training loss 1.526542\n",
            ">> Epoch 23 finished \tANN training loss 1.529343\n",
            ">> Epoch 24 finished \tANN training loss 1.497098\n",
            ">> Epoch 25 finished \tANN training loss 1.551028\n",
            ">> Epoch 26 finished \tANN training loss 1.448715\n",
            ">> Epoch 27 finished \tANN training loss 1.457039\n",
            ">> Epoch 28 finished \tANN training loss 1.531772\n",
            ">> Epoch 29 finished \tANN training loss 1.426155\n",
            ">> Epoch 30 finished \tANN training loss 1.395560\n",
            ">> Epoch 31 finished \tANN training loss 1.373403\n",
            ">> Epoch 32 finished \tANN training loss 1.393595\n",
            ">> Epoch 33 finished \tANN training loss 1.356537\n",
            ">> Epoch 34 finished \tANN training loss 1.338161\n",
            ">> Epoch 35 finished \tANN training loss 1.357755\n",
            ">> Epoch 36 finished \tANN training loss 1.334401\n",
            ">> Epoch 37 finished \tANN training loss 1.326859\n",
            ">> Epoch 38 finished \tANN training loss 1.294037\n",
            ">> Epoch 39 finished \tANN training loss 1.310475\n",
            ">> Epoch 40 finished \tANN training loss 1.285604\n",
            ">> Epoch 41 finished \tANN training loss 1.251143\n",
            ">> Epoch 42 finished \tANN training loss 1.238622\n",
            ">> Epoch 43 finished \tANN training loss 1.244420\n",
            ">> Epoch 44 finished \tANN training loss 1.227694\n",
            ">> Epoch 45 finished \tANN training loss 1.234250\n",
            ">> Epoch 46 finished \tANN training loss 1.192151\n",
            ">> Epoch 47 finished \tANN training loss 1.282872\n",
            ">> Epoch 48 finished \tANN training loss 1.202125\n",
            ">> Epoch 49 finished \tANN training loss 1.195783\n",
            ">> Epoch 50 finished \tANN training loss 1.173911\n",
            ">> Epoch 51 finished \tANN training loss 1.180761\n",
            ">> Epoch 52 finished \tANN training loss 1.126582\n",
            ">> Epoch 53 finished \tANN training loss 1.107668\n",
            ">> Epoch 54 finished \tANN training loss 1.080279\n",
            ">> Epoch 55 finished \tANN training loss 1.054442\n",
            ">> Epoch 56 finished \tANN training loss 1.064081\n",
            ">> Epoch 57 finished \tANN training loss 1.106891\n",
            ">> Epoch 58 finished \tANN training loss 1.017401\n",
            ">> Epoch 59 finished \tANN training loss 1.091074\n",
            ">> Epoch 60 finished \tANN training loss 1.101666\n",
            ">> Epoch 61 finished \tANN training loss 0.970878\n",
            ">> Epoch 62 finished \tANN training loss 0.990581\n",
            ">> Epoch 63 finished \tANN training loss 0.924880\n",
            ">> Epoch 64 finished \tANN training loss 0.933200\n",
            ">> Epoch 65 finished \tANN training loss 0.888013\n",
            ">> Epoch 66 finished \tANN training loss 0.914845\n",
            ">> Epoch 67 finished \tANN training loss 0.895561\n",
            ">> Epoch 68 finished \tANN training loss 0.862002\n",
            ">> Epoch 69 finished \tANN training loss 0.860283\n",
            ">> Epoch 70 finished \tANN training loss 0.926866\n",
            ">> Epoch 71 finished \tANN training loss 0.825624\n",
            ">> Epoch 72 finished \tANN training loss 0.955979\n",
            ">> Epoch 73 finished \tANN training loss 0.837455\n",
            ">> Epoch 74 finished \tANN training loss 0.838362\n",
            ">> Epoch 75 finished \tANN training loss 0.824579\n",
            ">> Epoch 76 finished \tANN training loss 0.837506\n",
            ">> Epoch 77 finished \tANN training loss 0.799540\n",
            ">> Epoch 78 finished \tANN training loss 0.782582\n",
            ">> Epoch 79 finished \tANN training loss 0.809945\n",
            ">> Epoch 80 finished \tANN training loss 0.776058\n",
            ">> Epoch 81 finished \tANN training loss 0.801965\n",
            ">> Epoch 82 finished \tANN training loss 0.743689\n",
            ">> Epoch 83 finished \tANN training loss 0.748219\n",
            ">> Epoch 84 finished \tANN training loss 0.725424\n",
            ">> Epoch 85 finished \tANN training loss 0.707048\n",
            ">> Epoch 86 finished \tANN training loss 0.760290\n",
            ">> Epoch 87 finished \tANN training loss 0.732380\n",
            ">> Epoch 88 finished \tANN training loss 0.725342\n",
            ">> Epoch 89 finished \tANN training loss 0.722347\n",
            ">> Epoch 90 finished \tANN training loss 0.747846\n",
            ">> Epoch 91 finished \tANN training loss 0.766685\n",
            ">> Epoch 92 finished \tANN training loss 0.678031\n",
            ">> Epoch 93 finished \tANN training loss 0.728679\n",
            ">> Epoch 94 finished \tANN training loss 0.665033\n",
            ">> Epoch 95 finished \tANN training loss 0.704792\n",
            ">> Epoch 96 finished \tANN training loss 0.666352\n",
            ">> Epoch 97 finished \tANN training loss 0.711128\n",
            ">> Epoch 98 finished \tANN training loss 0.653001\n",
            ">> Epoch 99 finished \tANN training loss 0.628350\n",
            "[END] Fine tuning step\n",
            "\n",
            "Accuracy: 0.754902\n",
            "Confusion Matrix:\n",
            " [[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 10  0  1  0  0  0  0  0  0  1  0  0  0  0  0]\n",
            " [ 0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  6  0  2  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0 10  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  0  1  0  0  0 13  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0  7  0  4]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  9  0]\n",
            " [ 0  0  1  0  0  0  2  3  1  0  0  0  0  0  0  4  4]]\n"
          ]
        }
      ],
      "source": [
        "#case 9\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(3529)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "\n",
        "\n",
        "dataset = pd.read_csv(\"Instruments.csv\")\n",
        "dataset = dataset.drop([\"File Name\"], axis=1)\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "dataset['Instrument'] = le.fit_transform(dataset['Instrument'])\n",
        "\n",
        "X = np.array(dataset.drop([\"Instrument\"], axis=1))\n",
        "Y = np.array(dataset.Instrument.values)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[128, 128, 128, 128],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.4,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='sigmoid',\n",
        "                                         dropout_p=0.2)\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print('\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01d067c4",
      "metadata": {
        "id": "01d067c4",
        "outputId": "cfca926c-7c68-4f20-b9bc-af6115df2123"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 41.780271\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 40.872977\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 41.017986\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 41.373823\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 41.698571\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 41.948013\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 42.196067\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 42.439778\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 42.863548\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 42.649242\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 14.179907\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 10.724631\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 9.625305\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 8.980324\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 8.484160\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 7.885944\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 7.560121\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 6.955149\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 6.810843\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 6.380751\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 5.757024\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 4.113161\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 3.063645\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 2.526045\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 2.097313\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 1.734041\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 1.423209\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 1.144207\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 1.041854\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.907573\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 4.189174\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 2.415335\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 1.955680\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 1.743029\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 1.464093\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 1.215696\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 1.052109\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.962401\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.828475\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.752980\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss 2.355754\n",
            ">> Epoch 1 finished \tANN training loss 2.005809\n",
            ">> Epoch 2 finished \tANN training loss 1.949715\n",
            ">> Epoch 3 finished \tANN training loss 1.816342\n",
            ">> Epoch 4 finished \tANN training loss 1.468088\n",
            ">> Epoch 5 finished \tANN training loss 1.378142\n",
            ">> Epoch 6 finished \tANN training loss 1.732937\n",
            ">> Epoch 7 finished \tANN training loss 1.304914\n",
            ">> Epoch 8 finished \tANN training loss 1.208001\n",
            ">> Epoch 9 finished \tANN training loss 1.296047\n",
            ">> Epoch 10 finished \tANN training loss 1.338111\n",
            ">> Epoch 11 finished \tANN training loss 1.184829\n",
            ">> Epoch 12 finished \tANN training loss 1.196126\n",
            ">> Epoch 13 finished \tANN training loss 1.291828\n",
            ">> Epoch 14 finished \tANN training loss 0.966330\n",
            ">> Epoch 15 finished \tANN training loss 1.119303\n",
            ">> Epoch 16 finished \tANN training loss 1.046144\n",
            ">> Epoch 17 finished \tANN training loss 1.036193\n",
            ">> Epoch 18 finished \tANN training loss 0.796963\n",
            ">> Epoch 19 finished \tANN training loss 0.966526\n",
            ">> Epoch 20 finished \tANN training loss 0.884428\n",
            ">> Epoch 21 finished \tANN training loss 0.799144\n",
            ">> Epoch 22 finished \tANN training loss 1.092183\n",
            ">> Epoch 23 finished \tANN training loss 0.710476\n",
            ">> Epoch 24 finished \tANN training loss 0.769813\n",
            ">> Epoch 25 finished \tANN training loss 1.368138\n",
            ">> Epoch 26 finished \tANN training loss 0.828462\n",
            ">> Epoch 27 finished \tANN training loss 0.812755\n",
            ">> Epoch 28 finished \tANN training loss 0.726576\n",
            ">> Epoch 29 finished \tANN training loss 0.920830\n",
            ">> Epoch 30 finished \tANN training loss 0.821545\n",
            ">> Epoch 31 finished \tANN training loss 0.601399\n",
            ">> Epoch 32 finished \tANN training loss 0.741971\n",
            ">> Epoch 33 finished \tANN training loss 0.607226\n",
            ">> Epoch 34 finished \tANN training loss 0.659265\n",
            ">> Epoch 35 finished \tANN training loss 0.672722\n",
            ">> Epoch 36 finished \tANN training loss 1.319239\n",
            ">> Epoch 37 finished \tANN training loss 0.686871\n",
            ">> Epoch 38 finished \tANN training loss 0.555630\n",
            ">> Epoch 39 finished \tANN training loss 0.632449\n",
            ">> Epoch 40 finished \tANN training loss 0.636977\n",
            ">> Epoch 41 finished \tANN training loss 0.565965\n",
            ">> Epoch 42 finished \tANN training loss 0.552924\n",
            ">> Epoch 43 finished \tANN training loss 0.667722\n",
            ">> Epoch 44 finished \tANN training loss 0.747259\n",
            ">> Epoch 45 finished \tANN training loss 0.532093\n",
            ">> Epoch 46 finished \tANN training loss 0.589623\n",
            ">> Epoch 47 finished \tANN training loss 0.713966\n",
            ">> Epoch 48 finished \tANN training loss 0.498352\n",
            ">> Epoch 49 finished \tANN training loss 0.561103\n",
            ">> Epoch 50 finished \tANN training loss 0.566664\n",
            ">> Epoch 51 finished \tANN training loss 0.807969\n",
            ">> Epoch 52 finished \tANN training loss 0.521493\n",
            ">> Epoch 53 finished \tANN training loss 0.504521\n",
            ">> Epoch 54 finished \tANN training loss 0.541450\n",
            ">> Epoch 55 finished \tANN training loss 0.443279\n",
            ">> Epoch 56 finished \tANN training loss 0.606393\n",
            ">> Epoch 57 finished \tANN training loss 0.653897\n",
            ">> Epoch 58 finished \tANN training loss 0.602503\n",
            ">> Epoch 59 finished \tANN training loss 0.574262\n",
            ">> Epoch 60 finished \tANN training loss 0.541535\n",
            ">> Epoch 61 finished \tANN training loss 0.525864\n",
            ">> Epoch 62 finished \tANN training loss 0.444652\n",
            ">> Epoch 63 finished \tANN training loss 0.430767\n",
            ">> Epoch 64 finished \tANN training loss 0.644912\n",
            ">> Epoch 65 finished \tANN training loss 0.474384\n",
            ">> Epoch 66 finished \tANN training loss 0.450690\n",
            ">> Epoch 67 finished \tANN training loss 0.492417\n",
            ">> Epoch 68 finished \tANN training loss 0.621144\n",
            ">> Epoch 69 finished \tANN training loss 0.395571\n",
            ">> Epoch 70 finished \tANN training loss 0.458535\n",
            ">> Epoch 71 finished \tANN training loss 0.382509\n",
            ">> Epoch 72 finished \tANN training loss 0.530205\n",
            ">> Epoch 73 finished \tANN training loss 0.546226\n",
            ">> Epoch 74 finished \tANN training loss 0.395878\n",
            ">> Epoch 75 finished \tANN training loss 0.387898\n",
            ">> Epoch 76 finished \tANN training loss 0.364658\n",
            ">> Epoch 77 finished \tANN training loss 0.491180\n",
            ">> Epoch 78 finished \tANN training loss 0.339123\n",
            ">> Epoch 79 finished \tANN training loss 0.460687\n",
            ">> Epoch 80 finished \tANN training loss 0.424633\n",
            ">> Epoch 81 finished \tANN training loss 0.486973\n",
            ">> Epoch 82 finished \tANN training loss 0.357474\n",
            ">> Epoch 83 finished \tANN training loss 0.382459\n",
            ">> Epoch 84 finished \tANN training loss 0.313187\n",
            ">> Epoch 85 finished \tANN training loss 0.330671\n",
            ">> Epoch 86 finished \tANN training loss 0.360356\n",
            ">> Epoch 87 finished \tANN training loss 0.633519\n",
            ">> Epoch 88 finished \tANN training loss 0.728780\n",
            ">> Epoch 89 finished \tANN training loss 0.295521\n",
            ">> Epoch 90 finished \tANN training loss 0.308737\n",
            ">> Epoch 91 finished \tANN training loss 0.480726\n",
            ">> Epoch 92 finished \tANN training loss 0.407640\n",
            ">> Epoch 93 finished \tANN training loss 0.310695\n",
            ">> Epoch 94 finished \tANN training loss 0.247827\n",
            ">> Epoch 95 finished \tANN training loss 0.411460\n",
            ">> Epoch 96 finished \tANN training loss 0.351295\n",
            ">> Epoch 97 finished \tANN training loss 0.246896\n",
            ">> Epoch 98 finished \tANN training loss 0.243083\n",
            ">> Epoch 99 finished \tANN training loss 0.299315\n",
            "[END] Fine tuning step\n",
            "\n",
            "Accuracy: 0.857843\n",
            "Confusion Matrix:\n",
            " [[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 11  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  6  0  2  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  4  0  7  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  2]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  9  0]\n",
            " [ 0  0  1  0  0  0  0  0  1  0  0  0  0  0  1  3  9]]\n"
          ]
        }
      ],
      "source": [
        "#case 10\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(3529)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "\n",
        "\n",
        "dataset = pd.read_csv(\"Instruments.csv\")\n",
        "dataset = dataset.drop([\"File Name\"], axis=1)\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "dataset['Instrument'] = le.fit_transform(dataset['Instrument'])\n",
        "\n",
        "X = np.array(dataset.drop([\"Instrument\"], axis=1))\n",
        "Y = np.array(dataset.Instrument.values)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[256, 256, 256, 256],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.4,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='sigmoid',\n",
        "                                         dropout_p=0.05)\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print('\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cc2de2c",
      "metadata": {
        "id": "2cc2de2c",
        "outputId": "851c9102-0013-488d-a3a5-b4dbde696966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 41.792308\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 40.697907\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 40.745301\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 40.877579\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 41.123398\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 41.327932\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 41.602009\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 41.763390\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 42.133638\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 41.999716\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 13.749287\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 10.896676\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 10.036325\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 9.319138\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 8.862726\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 8.321328\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 7.879983\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 7.386158\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 7.215208\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 6.832676\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 6.196856\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 4.699625\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 3.261836\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 2.646699\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 2.082705\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 1.679480\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 1.360283\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 1.247703\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 1.059702\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.925052\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 3.949530\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 2.221192\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 1.842948\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 1.674798\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 1.392542\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 1.244112\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 1.069062\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.922722\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.873899\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.741341\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss 2.303955\n",
            ">> Epoch 1 finished \tANN training loss 1.943863\n",
            ">> Epoch 2 finished \tANN training loss 2.000633\n",
            ">> Epoch 3 finished \tANN training loss 1.531922\n",
            ">> Epoch 4 finished \tANN training loss 1.559560\n",
            ">> Epoch 5 finished \tANN training loss 1.439424\n",
            ">> Epoch 6 finished \tANN training loss 1.793061\n",
            ">> Epoch 7 finished \tANN training loss 1.361017\n",
            ">> Epoch 8 finished \tANN training loss 1.248379\n",
            ">> Epoch 9 finished \tANN training loss 1.297007\n",
            ">> Epoch 10 finished \tANN training loss 1.270400\n",
            ">> Epoch 11 finished \tANN training loss 1.072484\n",
            ">> Epoch 12 finished \tANN training loss 1.065917\n",
            ">> Epoch 13 finished \tANN training loss 1.206617\n",
            ">> Epoch 14 finished \tANN training loss 0.970444\n",
            ">> Epoch 15 finished \tANN training loss 1.100040\n",
            ">> Epoch 16 finished \tANN training loss 0.990905\n",
            ">> Epoch 17 finished \tANN training loss 0.926904\n",
            ">> Epoch 18 finished \tANN training loss 0.989692\n",
            ">> Epoch 19 finished \tANN training loss 0.954614\n",
            ">> Epoch 20 finished \tANN training loss 0.921462\n",
            ">> Epoch 21 finished \tANN training loss 0.916566\n",
            ">> Epoch 22 finished \tANN training loss 0.789039\n",
            ">> Epoch 23 finished \tANN training loss 0.955643\n",
            ">> Epoch 24 finished \tANN training loss 0.683763\n",
            ">> Epoch 25 finished \tANN training loss 1.111770\n",
            ">> Epoch 26 finished \tANN training loss 0.810240\n",
            ">> Epoch 27 finished \tANN training loss 0.802449\n",
            ">> Epoch 28 finished \tANN training loss 0.831219\n",
            ">> Epoch 29 finished \tANN training loss 0.703080\n",
            ">> Epoch 30 finished \tANN training loss 0.751760\n",
            ">> Epoch 31 finished \tANN training loss 0.987825\n",
            ">> Epoch 32 finished \tANN training loss 0.728653\n",
            ">> Epoch 33 finished \tANN training loss 0.605071\n",
            ">> Epoch 34 finished \tANN training loss 0.819282\n",
            ">> Epoch 35 finished \tANN training loss 0.716283\n",
            ">> Epoch 36 finished \tANN training loss 0.839047\n",
            ">> Epoch 37 finished \tANN training loss 0.659773\n",
            ">> Epoch 38 finished \tANN training loss 0.572167\n",
            ">> Epoch 39 finished \tANN training loss 0.534373\n",
            ">> Epoch 40 finished \tANN training loss 0.544591\n",
            ">> Epoch 41 finished \tANN training loss 0.573683\n",
            ">> Epoch 42 finished \tANN training loss 0.520078\n",
            ">> Epoch 43 finished \tANN training loss 0.724189\n",
            ">> Epoch 44 finished \tANN training loss 0.870827\n",
            ">> Epoch 45 finished \tANN training loss 0.642290\n",
            ">> Epoch 46 finished \tANN training loss 0.502335\n",
            ">> Epoch 47 finished \tANN training loss 0.575561\n",
            ">> Epoch 48 finished \tANN training loss 0.479302\n",
            ">> Epoch 49 finished \tANN training loss 0.470576\n",
            ">> Epoch 50 finished \tANN training loss 0.510612\n",
            ">> Epoch 51 finished \tANN training loss 0.571177\n",
            ">> Epoch 52 finished \tANN training loss 0.502410\n",
            ">> Epoch 53 finished \tANN training loss 0.601242\n",
            ">> Epoch 54 finished \tANN training loss 0.475851\n",
            ">> Epoch 55 finished \tANN training loss 0.661030\n",
            ">> Epoch 56 finished \tANN training loss 0.400963\n",
            ">> Epoch 57 finished \tANN training loss 0.525064\n",
            ">> Epoch 58 finished \tANN training loss 0.421402\n",
            ">> Epoch 59 finished \tANN training loss 0.568796\n",
            ">> Epoch 60 finished \tANN training loss 0.512244\n",
            ">> Epoch 61 finished \tANN training loss 0.463851\n",
            ">> Epoch 62 finished \tANN training loss 0.402834\n",
            ">> Epoch 63 finished \tANN training loss 0.513126\n",
            ">> Epoch 64 finished \tANN training loss 0.670645\n",
            ">> Epoch 65 finished \tANN training loss 1.002682\n",
            ">> Epoch 66 finished \tANN training loss 0.373528\n",
            ">> Epoch 67 finished \tANN training loss 0.464029\n",
            ">> Epoch 68 finished \tANN training loss 0.445517\n",
            ">> Epoch 69 finished \tANN training loss 0.511435\n",
            ">> Epoch 70 finished \tANN training loss 0.706556\n",
            ">> Epoch 71 finished \tANN training loss 0.391917\n",
            ">> Epoch 72 finished \tANN training loss 0.424611\n",
            ">> Epoch 73 finished \tANN training loss 0.362159\n",
            ">> Epoch 74 finished \tANN training loss 0.381115\n",
            ">> Epoch 75 finished \tANN training loss 0.321061\n",
            ">> Epoch 76 finished \tANN training loss 0.338619\n",
            ">> Epoch 77 finished \tANN training loss 0.424649\n",
            ">> Epoch 78 finished \tANN training loss 0.333186\n",
            ">> Epoch 79 finished \tANN training loss 0.335362\n",
            ">> Epoch 80 finished \tANN training loss 0.375474\n",
            ">> Epoch 81 finished \tANN training loss 0.392937\n",
            ">> Epoch 82 finished \tANN training loss 0.351414\n",
            ">> Epoch 83 finished \tANN training loss 0.320896\n",
            ">> Epoch 84 finished \tANN training loss 0.374062\n",
            ">> Epoch 85 finished \tANN training loss 0.313674\n",
            ">> Epoch 86 finished \tANN training loss 0.330555\n",
            ">> Epoch 87 finished \tANN training loss 0.304709\n",
            ">> Epoch 88 finished \tANN training loss 0.310597\n",
            ">> Epoch 89 finished \tANN training loss 0.318290\n",
            ">> Epoch 90 finished \tANN training loss 0.359511\n",
            ">> Epoch 91 finished \tANN training loss 0.328263\n",
            ">> Epoch 92 finished \tANN training loss 0.311251\n",
            ">> Epoch 93 finished \tANN training loss 0.362394\n",
            ">> Epoch 94 finished \tANN training loss 0.302975\n",
            ">> Epoch 95 finished \tANN training loss 0.317551\n",
            ">> Epoch 96 finished \tANN training loss 0.351703\n",
            ">> Epoch 97 finished \tANN training loss 0.329673\n",
            ">> Epoch 98 finished \tANN training loss 0.299616\n",
            ">> Epoch 99 finished \tANN training loss 0.285132\n",
            "[END] Fine tuning step\n",
            "\n",
            "Accuracy: 0.897059\n",
            "Confusion Matrix:\n",
            " [[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  6  0  2  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0 10  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0 14  0  0  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  0  9  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  1]\n",
            " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  1  0  0  1  0 12]]\n"
          ]
        }
      ],
      "source": [
        "#case 11\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(3529)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "\n",
        "\n",
        "dataset = pd.read_csv(\"Instruments.csv\")\n",
        "dataset = dataset.drop([\"File Name\"], axis=1)\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "dataset['Instrument'] = le.fit_transform(dataset['Instrument'])\n",
        "\n",
        "X = np.array(dataset.drop([\"Instrument\"], axis=1))\n",
        "Y = np.array(dataset.Instrument.values)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[256, 256, 256, 256],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.4,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='sigmoid',\n",
        "                                         dropout_p=0.1)\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print('\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31602d61",
      "metadata": {
        "id": "31602d61",
        "outputId": "6b15089c-7015-4cee-8516-26bbaea4035c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 41.928273\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 41.062688\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 41.101849\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 41.365208\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 41.580365\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 41.780221\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 41.989691\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 42.163667\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 42.410279\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 42.337359\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 14.425925\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 10.897882\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 9.837923\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 9.177402\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 8.672123\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 8.027297\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 7.678715\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 7.128404\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 7.032723\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 6.574803\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 6.645475\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 4.554062\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 3.460196\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 2.608315\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 2.176655\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 1.982105\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 1.601931\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 1.270529\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 1.165354\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.980679\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 4.217915\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 2.180746\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 1.848991\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 1.479886\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 1.336478\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 1.159839\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.973260\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.918541\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.740847\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.671451\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss 2.299225\n",
            ">> Epoch 1 finished \tANN training loss 2.094565\n",
            ">> Epoch 2 finished \tANN training loss 2.055731\n",
            ">> Epoch 3 finished \tANN training loss 2.129252\n",
            ">> Epoch 4 finished \tANN training loss 1.651600\n",
            ">> Epoch 5 finished \tANN training loss 1.491005\n",
            ">> Epoch 6 finished \tANN training loss 1.797554\n",
            ">> Epoch 7 finished \tANN training loss 1.563263\n",
            ">> Epoch 8 finished \tANN training loss 1.392459\n",
            ">> Epoch 9 finished \tANN training loss 1.443025\n",
            ">> Epoch 10 finished \tANN training loss 1.463212\n",
            ">> Epoch 11 finished \tANN training loss 1.301476\n",
            ">> Epoch 12 finished \tANN training loss 1.207085\n",
            ">> Epoch 13 finished \tANN training loss 1.442973\n",
            ">> Epoch 14 finished \tANN training loss 1.239788\n",
            ">> Epoch 15 finished \tANN training loss 1.191382\n",
            ">> Epoch 16 finished \tANN training loss 1.172073\n",
            ">> Epoch 17 finished \tANN training loss 1.092896\n",
            ">> Epoch 18 finished \tANN training loss 1.051139\n",
            ">> Epoch 19 finished \tANN training loss 1.121554\n",
            ">> Epoch 20 finished \tANN training loss 1.149510\n",
            ">> Epoch 21 finished \tANN training loss 1.085826\n",
            ">> Epoch 22 finished \tANN training loss 0.965453\n",
            ">> Epoch 23 finished \tANN training loss 0.944914\n",
            ">> Epoch 24 finished \tANN training loss 0.970495\n",
            ">> Epoch 25 finished \tANN training loss 0.902461\n",
            ">> Epoch 26 finished \tANN training loss 0.856993\n",
            ">> Epoch 27 finished \tANN training loss 0.955770\n",
            ">> Epoch 28 finished \tANN training loss 1.027274\n",
            ">> Epoch 29 finished \tANN training loss 0.857773\n",
            ">> Epoch 30 finished \tANN training loss 0.852348\n",
            ">> Epoch 31 finished \tANN training loss 0.889136\n",
            ">> Epoch 32 finished \tANN training loss 0.859254\n",
            ">> Epoch 33 finished \tANN training loss 0.787451\n",
            ">> Epoch 34 finished \tANN training loss 0.823568\n",
            ">> Epoch 35 finished \tANN training loss 0.880880\n",
            ">> Epoch 36 finished \tANN training loss 0.783373\n",
            ">> Epoch 37 finished \tANN training loss 0.878841\n",
            ">> Epoch 38 finished \tANN training loss 0.762410\n",
            ">> Epoch 39 finished \tANN training loss 0.925957\n",
            ">> Epoch 40 finished \tANN training loss 0.836307\n",
            ">> Epoch 41 finished \tANN training loss 0.707972\n",
            ">> Epoch 42 finished \tANN training loss 0.768072\n",
            ">> Epoch 43 finished \tANN training loss 0.729777\n",
            ">> Epoch 44 finished \tANN training loss 0.858946\n",
            ">> Epoch 45 finished \tANN training loss 0.731328\n",
            ">> Epoch 46 finished \tANN training loss 0.702854\n",
            ">> Epoch 47 finished \tANN training loss 0.747056\n",
            ">> Epoch 48 finished \tANN training loss 0.682895\n",
            ">> Epoch 49 finished \tANN training loss 0.818870\n",
            ">> Epoch 50 finished \tANN training loss 0.665726\n",
            ">> Epoch 51 finished \tANN training loss 0.716408\n",
            ">> Epoch 52 finished \tANN training loss 0.625661\n",
            ">> Epoch 53 finished \tANN training loss 0.659843\n",
            ">> Epoch 54 finished \tANN training loss 0.663048\n",
            ">> Epoch 55 finished \tANN training loss 0.585904\n",
            ">> Epoch 56 finished \tANN training loss 0.637196\n",
            ">> Epoch 57 finished \tANN training loss 0.667233\n",
            ">> Epoch 58 finished \tANN training loss 0.584763\n",
            ">> Epoch 59 finished \tANN training loss 0.752489\n",
            ">> Epoch 60 finished \tANN training loss 0.657930\n",
            ">> Epoch 61 finished \tANN training loss 0.616332\n",
            ">> Epoch 62 finished \tANN training loss 0.654013\n",
            ">> Epoch 63 finished \tANN training loss 0.616264\n",
            ">> Epoch 64 finished \tANN training loss 0.688015\n",
            ">> Epoch 65 finished \tANN training loss 0.565256\n",
            ">> Epoch 66 finished \tANN training loss 0.541758\n",
            ">> Epoch 67 finished \tANN training loss 0.529538\n",
            ">> Epoch 68 finished \tANN training loss 0.518958\n",
            ">> Epoch 69 finished \tANN training loss 0.608546\n",
            ">> Epoch 70 finished \tANN training loss 0.854384\n",
            ">> Epoch 71 finished \tANN training loss 0.542631\n",
            ">> Epoch 72 finished \tANN training loss 0.629748\n",
            ">> Epoch 73 finished \tANN training loss 0.549381\n",
            ">> Epoch 74 finished \tANN training loss 0.554504\n",
            ">> Epoch 75 finished \tANN training loss 0.643439\n",
            ">> Epoch 76 finished \tANN training loss 0.545011\n",
            ">> Epoch 77 finished \tANN training loss 0.509667\n",
            ">> Epoch 78 finished \tANN training loss 0.625169\n",
            ">> Epoch 79 finished \tANN training loss 0.559927\n",
            ">> Epoch 80 finished \tANN training loss 0.629732\n",
            ">> Epoch 81 finished \tANN training loss 0.535591\n",
            ">> Epoch 82 finished \tANN training loss 0.512410\n",
            ">> Epoch 83 finished \tANN training loss 0.521489\n",
            ">> Epoch 84 finished \tANN training loss 0.478122\n",
            ">> Epoch 85 finished \tANN training loss 0.445746\n",
            ">> Epoch 86 finished \tANN training loss 0.481189\n",
            ">> Epoch 87 finished \tANN training loss 0.467566\n",
            ">> Epoch 88 finished \tANN training loss 0.516752\n",
            ">> Epoch 89 finished \tANN training loss 0.448772\n",
            ">> Epoch 90 finished \tANN training loss 0.580619\n",
            ">> Epoch 91 finished \tANN training loss 0.514983\n",
            ">> Epoch 92 finished \tANN training loss 0.485222\n",
            ">> Epoch 93 finished \tANN training loss 0.448501\n",
            ">> Epoch 94 finished \tANN training loss 0.578910\n",
            ">> Epoch 95 finished \tANN training loss 0.402924\n",
            ">> Epoch 96 finished \tANN training loss 0.465109\n",
            ">> Epoch 97 finished \tANN training loss 0.477062\n",
            ">> Epoch 98 finished \tANN training loss 0.492936\n",
            ">> Epoch 99 finished \tANN training loss 0.441270\n",
            "[END] Fine tuning step\n",
            "\n",
            "Accuracy: 0.789216\n",
            "Confusion Matrix:\n",
            " [[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0]\n",
            " [ 0  0  9  0  0  0  0  0  0  0  6  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0]\n",
            " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0 10  0  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  9  0]\n",
            " [ 0  0  0  0  0  0  1  0  0  0  0  1  0  0  2  3  8]]\n"
          ]
        }
      ],
      "source": [
        "#case 12\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(3529)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "\n",
        "\n",
        "dataset = pd.read_csv(\"Instruments.csv\")\n",
        "dataset = dataset.drop([\"File Name\"], axis=1)\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "dataset['Instrument'] = le.fit_transform(dataset['Instrument'])\n",
        "\n",
        "X = np.array(dataset.drop([\"Instrument\"], axis=1))\n",
        "Y = np.array(dataset.Instrument.values)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[256, 256, 256, 256],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.4,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='sigmoid',\n",
        "                                         dropout_p=0.2)\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print('\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1466d996",
      "metadata": {
        "id": "1466d996",
        "outputId": "e8f840d4-b045-4602-da99-760b87df7f0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 43.996420\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 42.872291\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 42.578621\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 42.563326\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 42.745222\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 42.918616\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 43.089202\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 43.303874\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 43.557284\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 43.464297\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 9.802981\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 6.206737\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 4.927590\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 4.479526\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 4.279783\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 4.175113\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 3.988726\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 3.847451\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 3.718203\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 3.574889\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 3.725893\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 1.769416\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 0.991826\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.793316\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.805093\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.699267\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.685677\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.630998\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.595160\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.570329\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 2.900568\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 1.137552\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 0.497561\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.333553\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.268621\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.253052\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.232243\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.229902\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.215756\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.214141\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 2.834458\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 0.821829\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 0.406224\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.247149\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.241908\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.182438\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.159523\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.169832\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.142858\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.134254\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 2.700932\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 0.854578\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 0.315472\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.200918\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.143773\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.135846\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.137077\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.114108\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.114964\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.091172\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss 2.248294\n",
            ">> Epoch 1 finished \tANN training loss 2.072932\n",
            ">> Epoch 2 finished \tANN training loss 2.177604\n",
            ">> Epoch 3 finished \tANN training loss 1.989425\n",
            ">> Epoch 4 finished \tANN training loss 2.022398\n",
            ">> Epoch 5 finished \tANN training loss 1.861591\n",
            ">> Epoch 6 finished \tANN training loss 1.825949\n",
            ">> Epoch 7 finished \tANN training loss 1.931408\n",
            ">> Epoch 8 finished \tANN training loss 1.775237\n",
            ">> Epoch 9 finished \tANN training loss 1.752228\n",
            ">> Epoch 10 finished \tANN training loss 1.689339\n",
            ">> Epoch 11 finished \tANN training loss 1.613612\n",
            ">> Epoch 12 finished \tANN training loss 1.703737\n",
            ">> Epoch 13 finished \tANN training loss 1.566033\n",
            ">> Epoch 14 finished \tANN training loss 1.588562\n",
            ">> Epoch 15 finished \tANN training loss 1.563155\n",
            ">> Epoch 16 finished \tANN training loss 1.535912\n",
            ">> Epoch 17 finished \tANN training loss 1.854164\n",
            ">> Epoch 18 finished \tANN training loss 1.730469\n",
            ">> Epoch 19 finished \tANN training loss 1.503639\n",
            ">> Epoch 20 finished \tANN training loss 1.513533\n",
            ">> Epoch 21 finished \tANN training loss 1.482442\n",
            ">> Epoch 22 finished \tANN training loss 1.592499\n",
            ">> Epoch 23 finished \tANN training loss 1.431135\n",
            ">> Epoch 24 finished \tANN training loss 1.594574\n",
            ">> Epoch 25 finished \tANN training loss 1.630303\n",
            ">> Epoch 26 finished \tANN training loss 1.389851\n",
            ">> Epoch 27 finished \tANN training loss 1.451792\n",
            ">> Epoch 28 finished \tANN training loss 1.393417\n",
            ">> Epoch 29 finished \tANN training loss 1.366777\n",
            ">> Epoch 30 finished \tANN training loss 1.457555\n",
            ">> Epoch 31 finished \tANN training loss 1.434905\n",
            ">> Epoch 32 finished \tANN training loss 1.512418\n",
            ">> Epoch 33 finished \tANN training loss 1.322252\n",
            ">> Epoch 34 finished \tANN training loss 1.457784\n",
            ">> Epoch 35 finished \tANN training loss 1.296240\n",
            ">> Epoch 36 finished \tANN training loss 1.328582\n",
            ">> Epoch 37 finished \tANN training loss 1.401475\n",
            ">> Epoch 38 finished \tANN training loss 1.319411\n",
            ">> Epoch 39 finished \tANN training loss 1.239302\n",
            ">> Epoch 40 finished \tANN training loss 1.657244\n",
            ">> Epoch 41 finished \tANN training loss 1.344938\n",
            ">> Epoch 42 finished \tANN training loss 1.279983\n",
            ">> Epoch 43 finished \tANN training loss 1.812382\n",
            ">> Epoch 44 finished \tANN training loss 1.229697\n",
            ">> Epoch 45 finished \tANN training loss 1.176625\n",
            ">> Epoch 46 finished \tANN training loss 1.331004\n",
            ">> Epoch 47 finished \tANN training loss 1.203512\n",
            ">> Epoch 48 finished \tANN training loss 1.235551\n",
            ">> Epoch 49 finished \tANN training loss 1.219181\n",
            ">> Epoch 50 finished \tANN training loss 1.153909\n",
            ">> Epoch 51 finished \tANN training loss 1.154788\n",
            ">> Epoch 52 finished \tANN training loss 1.156716\n",
            ">> Epoch 53 finished \tANN training loss 1.271531\n",
            ">> Epoch 54 finished \tANN training loss 1.212051\n",
            ">> Epoch 55 finished \tANN training loss 1.099769\n",
            ">> Epoch 56 finished \tANN training loss 1.109878\n",
            ">> Epoch 57 finished \tANN training loss 1.106008\n",
            ">> Epoch 58 finished \tANN training loss 1.098744\n",
            ">> Epoch 59 finished \tANN training loss 1.164668\n",
            ">> Epoch 60 finished \tANN training loss 1.085275\n",
            ">> Epoch 61 finished \tANN training loss 1.223306\n",
            ">> Epoch 62 finished \tANN training loss 1.091146\n",
            ">> Epoch 63 finished \tANN training loss 1.078929\n",
            ">> Epoch 64 finished \tANN training loss 1.088696\n",
            ">> Epoch 65 finished \tANN training loss 1.043728\n",
            ">> Epoch 66 finished \tANN training loss 1.021376\n",
            ">> Epoch 67 finished \tANN training loss 1.420218\n",
            ">> Epoch 68 finished \tANN training loss 1.066512\n",
            ">> Epoch 69 finished \tANN training loss 1.283128\n",
            ">> Epoch 70 finished \tANN training loss 0.975086\n",
            ">> Epoch 71 finished \tANN training loss 1.003711\n",
            ">> Epoch 72 finished \tANN training loss 0.966193\n",
            ">> Epoch 73 finished \tANN training loss 1.474280\n",
            ">> Epoch 74 finished \tANN training loss 1.036891\n",
            ">> Epoch 75 finished \tANN training loss 1.074170\n",
            ">> Epoch 76 finished \tANN training loss 0.990111\n",
            ">> Epoch 77 finished \tANN training loss 0.979931\n",
            ">> Epoch 78 finished \tANN training loss 1.038214\n",
            ">> Epoch 79 finished \tANN training loss 0.936215\n",
            ">> Epoch 80 finished \tANN training loss 0.914436\n",
            ">> Epoch 81 finished \tANN training loss 0.909277\n",
            ">> Epoch 82 finished \tANN training loss 0.932924\n",
            ">> Epoch 83 finished \tANN training loss 0.943851\n",
            ">> Epoch 84 finished \tANN training loss 1.005406\n",
            ">> Epoch 85 finished \tANN training loss 0.935902\n",
            ">> Epoch 86 finished \tANN training loss 0.969766\n",
            ">> Epoch 87 finished \tANN training loss 0.866467\n",
            ">> Epoch 88 finished \tANN training loss 0.918294\n",
            ">> Epoch 89 finished \tANN training loss 0.896709\n",
            ">> Epoch 90 finished \tANN training loss 0.962043\n",
            ">> Epoch 91 finished \tANN training loss 0.983880\n",
            ">> Epoch 92 finished \tANN training loss 0.892380\n",
            ">> Epoch 93 finished \tANN training loss 0.881656\n",
            ">> Epoch 94 finished \tANN training loss 0.856115\n",
            ">> Epoch 95 finished \tANN training loss 0.951613\n",
            ">> Epoch 96 finished \tANN training loss 0.970311\n",
            ">> Epoch 97 finished \tANN training loss 0.841004\n",
            ">> Epoch 98 finished \tANN training loss 0.827221\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Epoch 99 finished \tANN training loss 0.894456\n",
            "[END] Fine tuning step\n",
            "\n",
            "Accuracy: 0.617647\n",
            "Confusion Matrix:\n",
            " [[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  5  0  0  0  0  0  0  0  0  0  0  0  2  1  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0]\n",
            " [ 0  0  0  5  0  2  0  0  0  0  0  0  0  0  0  4  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  6  0  2  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0 10  0  0  0  0  0  0  0  0]\n",
            " [ 0  2  0  0  0  0  1  0  0  0  0  3  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 14  1  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0]\n",
            " [ 0  3  0  0  0  0  0  0  0  0  5  0  0  0  4  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  7  2]\n",
            " [ 0  2  0  0  0  0  0  0  1  0  2  1  0  0  0  2  7]]\n"
          ]
        }
      ],
      "source": [
        "#case 13\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(3529)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "\n",
        "\n",
        "dataset = pd.read_csv(\"Instruments.csv\")\n",
        "dataset = dataset.drop([\"File Name\"], axis=1)\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "dataset['Instrument'] = le.fit_transform(dataset['Instrument'])\n",
        "\n",
        "\n",
        "X = np.array(dataset.drop([\"Instrument\"], axis=1))\n",
        "Y = np.array(dataset.Instrument.values)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[128, 128, 128, 128, 128, 128],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.4,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='sigmoid',\n",
        "                                         dropout_p=0.05)\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print('\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f5a72f9",
      "metadata": {
        "id": "0f5a72f9",
        "outputId": "c8678412-0385-4595-c2f5-930e00164b72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 43.609389\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 42.852918\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 42.818830\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 42.948735\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 43.098784\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 43.210891\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 43.344079\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 43.456196\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 43.823303\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 43.657357\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 10.006001\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 6.766770\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 5.402900\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 4.843395\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 4.601433\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 4.367920\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 4.198896\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 4.049663\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 3.886069\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 3.772066\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 3.487273\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 1.489269\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 0.965596\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.761787\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.755818\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.702527\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.681450\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.645232\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.620193\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.605889\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 2.788723\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 1.098556\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 0.495889\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.348530\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.273225\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.247271\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.262507\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.231410\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.226878\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.212868\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 3.120102\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 1.230270\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 0.503536\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.382528\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.297488\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.287956\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.242032\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.209689\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.192010\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.166104\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 2.667175\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 1.017357\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 0.393063\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.240559\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.184447\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.168247\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.141622\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.118455\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.120852\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.107916\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss 2.286046\n",
            ">> Epoch 1 finished \tANN training loss 2.084279\n",
            ">> Epoch 2 finished \tANN training loss 2.157613\n",
            ">> Epoch 3 finished \tANN training loss 2.015646\n",
            ">> Epoch 4 finished \tANN training loss 2.010698\n",
            ">> Epoch 5 finished \tANN training loss 1.912616\n",
            ">> Epoch 6 finished \tANN training loss 1.890512\n",
            ">> Epoch 7 finished \tANN training loss 1.973773\n",
            ">> Epoch 8 finished \tANN training loss 1.834459\n",
            ">> Epoch 9 finished \tANN training loss 1.795783\n",
            ">> Epoch 10 finished \tANN training loss 1.751677\n",
            ">> Epoch 11 finished \tANN training loss 1.680129\n",
            ">> Epoch 12 finished \tANN training loss 1.654729\n",
            ">> Epoch 13 finished \tANN training loss 1.668286\n",
            ">> Epoch 14 finished \tANN training loss 1.675589\n",
            ">> Epoch 15 finished \tANN training loss 1.626807\n",
            ">> Epoch 16 finished \tANN training loss 1.581257\n",
            ">> Epoch 17 finished \tANN training loss 1.908555\n",
            ">> Epoch 18 finished \tANN training loss 1.614903\n",
            ">> Epoch 19 finished \tANN training loss 1.657209\n",
            ">> Epoch 20 finished \tANN training loss 1.570308\n",
            ">> Epoch 21 finished \tANN training loss 1.585315\n",
            ">> Epoch 22 finished \tANN training loss 1.629024\n",
            ">> Epoch 23 finished \tANN training loss 1.539175\n",
            ">> Epoch 24 finished \tANN training loss 1.502236\n",
            ">> Epoch 25 finished \tANN training loss 1.625121\n",
            ">> Epoch 26 finished \tANN training loss 1.487644\n",
            ">> Epoch 27 finished \tANN training loss 1.466213\n",
            ">> Epoch 28 finished \tANN training loss 1.513992\n",
            ">> Epoch 29 finished \tANN training loss 1.480664\n",
            ">> Epoch 30 finished \tANN training loss 1.477660\n",
            ">> Epoch 31 finished \tANN training loss 1.549744\n",
            ">> Epoch 32 finished \tANN training loss 1.477133\n",
            ">> Epoch 33 finished \tANN training loss 1.463639\n",
            ">> Epoch 34 finished \tANN training loss 1.516390\n",
            ">> Epoch 35 finished \tANN training loss 1.440364\n",
            ">> Epoch 36 finished \tANN training loss 1.453493\n",
            ">> Epoch 37 finished \tANN training loss 1.365522\n",
            ">> Epoch 38 finished \tANN training loss 1.392066\n",
            ">> Epoch 39 finished \tANN training loss 1.317458\n",
            ">> Epoch 40 finished \tANN training loss 1.436495\n",
            ">> Epoch 41 finished \tANN training loss 1.336759\n",
            ">> Epoch 42 finished \tANN training loss 1.448644\n",
            ">> Epoch 43 finished \tANN training loss 1.331624\n",
            ">> Epoch 44 finished \tANN training loss 1.371016\n",
            ">> Epoch 45 finished \tANN training loss 1.263318\n",
            ">> Epoch 46 finished \tANN training loss 1.311395\n",
            ">> Epoch 47 finished \tANN training loss 1.299449\n",
            ">> Epoch 48 finished \tANN training loss 1.294016\n",
            ">> Epoch 49 finished \tANN training loss 1.300636\n",
            ">> Epoch 50 finished \tANN training loss 1.297210\n",
            ">> Epoch 51 finished \tANN training loss 1.262365\n",
            ">> Epoch 52 finished \tANN training loss 1.318717\n",
            ">> Epoch 53 finished \tANN training loss 1.319631\n",
            ">> Epoch 54 finished \tANN training loss 1.300252\n",
            ">> Epoch 55 finished \tANN training loss 1.481310\n",
            ">> Epoch 56 finished \tANN training loss 1.233731\n",
            ">> Epoch 57 finished \tANN training loss 1.255174\n",
            ">> Epoch 58 finished \tANN training loss 1.205952\n",
            ">> Epoch 59 finished \tANN training loss 1.225810\n",
            ">> Epoch 60 finished \tANN training loss 1.235041\n",
            ">> Epoch 61 finished \tANN training loss 1.273451\n",
            ">> Epoch 62 finished \tANN training loss 1.195080\n",
            ">> Epoch 63 finished \tANN training loss 1.179816\n",
            ">> Epoch 64 finished \tANN training loss 1.168583\n",
            ">> Epoch 65 finished \tANN training loss 1.278595\n",
            ">> Epoch 66 finished \tANN training loss 1.193485\n",
            ">> Epoch 67 finished \tANN training loss 1.285697\n",
            ">> Epoch 68 finished \tANN training loss 1.193301\n",
            ">> Epoch 69 finished \tANN training loss 1.252163\n",
            ">> Epoch 70 finished \tANN training loss 1.155391\n",
            ">> Epoch 71 finished \tANN training loss 1.159760\n",
            ">> Epoch 72 finished \tANN training loss 1.127603\n",
            ">> Epoch 73 finished \tANN training loss 1.147693\n",
            ">> Epoch 74 finished \tANN training loss 1.227342\n",
            ">> Epoch 75 finished \tANN training loss 1.210005\n",
            ">> Epoch 76 finished \tANN training loss 1.137557\n",
            ">> Epoch 77 finished \tANN training loss 1.136181\n",
            ">> Epoch 78 finished \tANN training loss 1.228256\n",
            ">> Epoch 79 finished \tANN training loss 1.145252\n",
            ">> Epoch 80 finished \tANN training loss 1.105463\n",
            ">> Epoch 81 finished \tANN training loss 1.142132\n",
            ">> Epoch 82 finished \tANN training loss 1.055376\n",
            ">> Epoch 83 finished \tANN training loss 1.085218\n",
            ">> Epoch 84 finished \tANN training loss 1.096447\n",
            ">> Epoch 85 finished \tANN training loss 1.071598\n",
            ">> Epoch 86 finished \tANN training loss 1.101200\n",
            ">> Epoch 87 finished \tANN training loss 1.055888\n",
            ">> Epoch 88 finished \tANN training loss 1.063743\n",
            ">> Epoch 89 finished \tANN training loss 1.150140\n",
            ">> Epoch 90 finished \tANN training loss 1.135835\n",
            ">> Epoch 91 finished \tANN training loss 1.130028\n",
            ">> Epoch 92 finished \tANN training loss 1.025904\n",
            ">> Epoch 93 finished \tANN training loss 1.014976\n",
            ">> Epoch 94 finished \tANN training loss 0.994553\n",
            ">> Epoch 95 finished \tANN training loss 1.050592\n",
            ">> Epoch 96 finished \tANN training loss 0.994025\n",
            ">> Epoch 97 finished \tANN training loss 1.067141\n",
            ">> Epoch 98 finished \tANN training loss 1.025416\n",
            ">> Epoch 99 finished \tANN training loss 1.061215\n",
            "[END] Fine tuning step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy: 0.563725\n",
            "Confusion Matrix:\n",
            " [[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  6  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0]\n",
            " [ 0  0  0  4  0  3  0  0  0  0  0  0  0  1  0  3  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  6  0  2  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0 10  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  4  0  1  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  8  0  0  6  1  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  2  0]\n",
            " [ 0  7  0  0  0  0  0  0  0  0  0  0  0  0  0  1  4]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  9  0]\n",
            " [ 0  2  0  0  0  0  0  0  1  0  0  1  0  0  0  7  4]]\n"
          ]
        }
      ],
      "source": [
        "#case 14\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(3529)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "\n",
        "\n",
        "dataset = pd.read_csv(\"Instruments.csv\")\n",
        "dataset = dataset.drop([\"File Name\"], axis=1)\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "dataset['Instrument'] = le.fit_transform(dataset['Instrument'])\n",
        "\n",
        "\n",
        "X = np.array(dataset.drop([\"Instrument\"], axis=1))\n",
        "Y = np.array(dataset.Instrument.values)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[128, 128, 128, 128, 128, 128],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.4,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='sigmoid',\n",
        "                                         dropout_p=0.1)\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print('\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3301d83f",
      "metadata": {
        "id": "3301d83f",
        "outputId": "2c6202dc-d14a-4b62-fcdb-5e1c3ac18624"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 43.886352\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 43.046046\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 42.805803\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 42.905842\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 43.020510\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 43.075038\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 43.240156\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 43.335682\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 43.542940\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 43.468387\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 11.087082\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 7.220903\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 5.597691\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 4.919397\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 4.708293\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 4.420802\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 4.239472\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 4.014754\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 3.897891\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 3.698362\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 3.981275\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 1.527598\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 0.938647\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.803073\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.766450\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.764909\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.676009\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.634078\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.605052\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.580835\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 3.501202\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 1.214631\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 0.583485\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.412185\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.345668\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.322766\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.293792\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.280508\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.277080\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.272022\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 2.793688\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 0.819042\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 0.394557\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.271191\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.231584\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.207396\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.212356\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.178923\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.188060\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.161279\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 2.781979\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 0.931701\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 0.361872\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.241981\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.219268\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.174720\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.179576\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.164090\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.149542\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.121886\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss 2.251842\n",
            ">> Epoch 1 finished \tANN training loss 2.067681\n",
            ">> Epoch 2 finished \tANN training loss 2.108968\n",
            ">> Epoch 3 finished \tANN training loss 1.943238\n",
            ">> Epoch 4 finished \tANN training loss 1.871515\n",
            ">> Epoch 5 finished \tANN training loss 1.776626\n",
            ">> Epoch 6 finished \tANN training loss 1.771562\n",
            ">> Epoch 7 finished \tANN training loss 1.891889\n",
            ">> Epoch 8 finished \tANN training loss 1.765934\n",
            ">> Epoch 9 finished \tANN training loss 1.759462\n",
            ">> Epoch 10 finished \tANN training loss 1.697486\n",
            ">> Epoch 11 finished \tANN training loss 1.698179\n",
            ">> Epoch 12 finished \tANN training loss 1.636817\n",
            ">> Epoch 13 finished \tANN training loss 1.638686\n",
            ">> Epoch 14 finished \tANN training loss 1.680025\n",
            ">> Epoch 15 finished \tANN training loss 1.598380\n",
            ">> Epoch 16 finished \tANN training loss 1.583075\n",
            ">> Epoch 17 finished \tANN training loss 1.835029\n",
            ">> Epoch 18 finished \tANN training loss 1.595403\n",
            ">> Epoch 19 finished \tANN training loss 1.576131\n",
            ">> Epoch 20 finished \tANN training loss 1.572081\n",
            ">> Epoch 21 finished \tANN training loss 1.550265\n",
            ">> Epoch 22 finished \tANN training loss 1.630539\n",
            ">> Epoch 23 finished \tANN training loss 1.517986\n",
            ">> Epoch 24 finished \tANN training loss 1.480456\n",
            ">> Epoch 25 finished \tANN training loss 1.493541\n",
            ">> Epoch 26 finished \tANN training loss 1.467597\n",
            ">> Epoch 27 finished \tANN training loss 1.464341\n",
            ">> Epoch 28 finished \tANN training loss 1.458393\n",
            ">> Epoch 29 finished \tANN training loss 1.442560\n",
            ">> Epoch 30 finished \tANN training loss 1.494634\n",
            ">> Epoch 31 finished \tANN training loss 1.434536\n",
            ">> Epoch 32 finished \tANN training loss 1.433157\n",
            ">> Epoch 33 finished \tANN training loss 1.609621\n",
            ">> Epoch 34 finished \tANN training loss 1.469514\n",
            ">> Epoch 35 finished \tANN training loss 1.380108\n",
            ">> Epoch 36 finished \tANN training loss 1.633837\n",
            ">> Epoch 37 finished \tANN training loss 1.370612\n",
            ">> Epoch 38 finished \tANN training loss 1.365816\n",
            ">> Epoch 39 finished \tANN training loss 1.344026\n",
            ">> Epoch 40 finished \tANN training loss 1.375883\n",
            ">> Epoch 41 finished \tANN training loss 1.355031\n",
            ">> Epoch 42 finished \tANN training loss 1.492809\n",
            ">> Epoch 43 finished \tANN training loss 1.329049\n",
            ">> Epoch 44 finished \tANN training loss 1.351697\n",
            ">> Epoch 45 finished \tANN training loss 1.316906\n",
            ">> Epoch 46 finished \tANN training loss 1.345269\n",
            ">> Epoch 47 finished \tANN training loss 1.360189\n",
            ">> Epoch 48 finished \tANN training loss 1.317899\n",
            ">> Epoch 49 finished \tANN training loss 1.409497\n",
            ">> Epoch 50 finished \tANN training loss 1.341151\n",
            ">> Epoch 51 finished \tANN training loss 1.331371\n",
            ">> Epoch 52 finished \tANN training loss 1.301675\n",
            ">> Epoch 53 finished \tANN training loss 1.343287\n",
            ">> Epoch 54 finished \tANN training loss 1.298209\n",
            ">> Epoch 55 finished \tANN training loss 1.341437\n",
            ">> Epoch 56 finished \tANN training loss 1.310105\n",
            ">> Epoch 57 finished \tANN training loss 1.331626\n",
            ">> Epoch 58 finished \tANN training loss 1.313174\n",
            ">> Epoch 59 finished \tANN training loss 1.327456\n",
            ">> Epoch 60 finished \tANN training loss 1.289324\n",
            ">> Epoch 61 finished \tANN training loss 1.295377\n",
            ">> Epoch 62 finished \tANN training loss 1.290536\n",
            ">> Epoch 63 finished \tANN training loss 1.249636\n",
            ">> Epoch 64 finished \tANN training loss 1.244046\n",
            ">> Epoch 65 finished \tANN training loss 1.317548\n",
            ">> Epoch 66 finished \tANN training loss 1.246024\n",
            ">> Epoch 67 finished \tANN training loss 1.270822\n",
            ">> Epoch 68 finished \tANN training loss 1.260268\n",
            ">> Epoch 69 finished \tANN training loss 1.262222\n",
            ">> Epoch 70 finished \tANN training loss 1.244859\n",
            ">> Epoch 71 finished \tANN training loss 1.258458\n",
            ">> Epoch 72 finished \tANN training loss 1.256479\n",
            ">> Epoch 73 finished \tANN training loss 1.226517\n",
            ">> Epoch 74 finished \tANN training loss 1.266147\n",
            ">> Epoch 75 finished \tANN training loss 1.279248\n",
            ">> Epoch 76 finished \tANN training loss 1.301465\n",
            ">> Epoch 77 finished \tANN training loss 1.341313\n",
            ">> Epoch 78 finished \tANN training loss 1.226209\n",
            ">> Epoch 79 finished \tANN training loss 1.211712\n",
            ">> Epoch 80 finished \tANN training loss 1.219206\n",
            ">> Epoch 81 finished \tANN training loss 1.246858\n",
            ">> Epoch 82 finished \tANN training loss 1.205429\n",
            ">> Epoch 83 finished \tANN training loss 1.220340\n",
            ">> Epoch 84 finished \tANN training loss 1.229771\n",
            ">> Epoch 85 finished \tANN training loss 1.239241\n",
            ">> Epoch 86 finished \tANN training loss 1.228428\n",
            ">> Epoch 87 finished \tANN training loss 1.298715\n",
            ">> Epoch 88 finished \tANN training loss 1.234928\n",
            ">> Epoch 89 finished \tANN training loss 1.221309\n",
            ">> Epoch 90 finished \tANN training loss 1.199273\n",
            ">> Epoch 91 finished \tANN training loss 1.204976\n",
            ">> Epoch 92 finished \tANN training loss 1.188726\n",
            ">> Epoch 93 finished \tANN training loss 1.275268\n",
            ">> Epoch 94 finished \tANN training loss 1.214669\n",
            ">> Epoch 95 finished \tANN training loss 1.225007\n",
            ">> Epoch 96 finished \tANN training loss 1.195816\n",
            ">> Epoch 97 finished \tANN training loss 1.239328\n",
            ">> Epoch 98 finished \tANN training loss 1.193926\n",
            ">> Epoch 99 finished \tANN training loss 1.222696\n",
            "[END] Fine tuning step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy: 0.495098\n",
            "Confusion Matrix:\n",
            " [[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  6  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0]\n",
            " [ 0  2  0  2  0  3  0  0  0  0  0  0  0  3  0  1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 3  0  0  0  0  0  3  0  2  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  2  0  1  2  0  1  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0]\n",
            " [ 0  7  0  0  0  0  0  5  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  8  1]\n",
            " [ 0  2  0  0  0  0  0  4  1  0  0  1  0  0  0  6  1]]\n"
          ]
        }
      ],
      "source": [
        "#case 15\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(3529)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "\n",
        "\n",
        "dataset = pd.read_csv(\"Instruments.csv\")\n",
        "dataset = dataset.drop([\"File Name\"], axis=1)\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "dataset['Instrument'] = le.fit_transform(dataset['Instrument'])\n",
        "\n",
        "\n",
        "X = np.array(dataset.drop([\"Instrument\"], axis=1))\n",
        "Y = np.array(dataset.Instrument.values)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[128, 128, 128, 128, 128, 128],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.4,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='sigmoid',\n",
        "                                         dropout_p=0.2)\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print('\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da8380ce",
      "metadata": {
        "id": "da8380ce",
        "outputId": "5f5d809a-2209-4b12-dfc6-5a9d001b5486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 41.881581\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 41.257958\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 41.323386\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 41.571337\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 41.877749\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 42.132660\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 42.289599\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 42.371411\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 42.527196\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 42.431652\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 14.721472\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 11.279943\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 10.174998\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 9.224299\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 8.430844\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 7.848715\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 7.580234\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 7.079891\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 6.873018\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 6.571279\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 6.626338\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 4.557794\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 3.496681\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 2.939007\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 2.444906\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 1.816902\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 1.533974\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 1.238105\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 1.138116\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 1.063996\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 4.074636\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 2.436015\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 2.064846\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 1.778906\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 1.386577\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 1.185548\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.935022\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.821247\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.633960\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.610639\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 4.347401\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 2.228135\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 1.711066\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 1.380954\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 1.191205\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 1.002162\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.756898\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.572574\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.480395\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.358597\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 3.600170\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 1.776046\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 1.509164\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 1.334722\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 1.169990\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.935144\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.775750\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.712667\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.503954\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.437597\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss 2.441036\n",
            ">> Epoch 1 finished \tANN training loss 1.792657\n",
            ">> Epoch 2 finished \tANN training loss 1.928725\n",
            ">> Epoch 3 finished \tANN training loss 1.599205\n",
            ">> Epoch 4 finished \tANN training loss 1.821750\n",
            ">> Epoch 5 finished \tANN training loss 1.534096\n",
            ">> Epoch 6 finished \tANN training loss 1.407854\n",
            ">> Epoch 7 finished \tANN training loss 1.712880\n",
            ">> Epoch 8 finished \tANN training loss 1.307491\n",
            ">> Epoch 9 finished \tANN training loss 1.267714\n",
            ">> Epoch 10 finished \tANN training loss 1.383784\n",
            ">> Epoch 11 finished \tANN training loss 1.331258\n",
            ">> Epoch 12 finished \tANN training loss 1.227321\n",
            ">> Epoch 13 finished \tANN training loss 1.125127\n",
            ">> Epoch 14 finished \tANN training loss 1.212347\n",
            ">> Epoch 15 finished \tANN training loss 1.048481\n",
            ">> Epoch 16 finished \tANN training loss 1.222216\n",
            ">> Epoch 17 finished \tANN training loss 1.127892\n",
            ">> Epoch 18 finished \tANN training loss 1.123433\n",
            ">> Epoch 19 finished \tANN training loss 1.256029\n",
            ">> Epoch 20 finished \tANN training loss 0.910242\n",
            ">> Epoch 21 finished \tANN training loss 0.917687\n",
            ">> Epoch 22 finished \tANN training loss 0.915742\n",
            ">> Epoch 23 finished \tANN training loss 0.994854\n",
            ">> Epoch 24 finished \tANN training loss 1.141139\n",
            ">> Epoch 25 finished \tANN training loss 1.167651\n",
            ">> Epoch 26 finished \tANN training loss 0.777356\n",
            ">> Epoch 27 finished \tANN training loss 0.789659\n",
            ">> Epoch 28 finished \tANN training loss 1.395347\n",
            ">> Epoch 29 finished \tANN training loss 0.911472\n",
            ">> Epoch 30 finished \tANN training loss 0.820440\n",
            ">> Epoch 31 finished \tANN training loss 0.774344\n",
            ">> Epoch 32 finished \tANN training loss 1.065869\n",
            ">> Epoch 33 finished \tANN training loss 0.790273\n",
            ">> Epoch 34 finished \tANN training loss 0.645244\n",
            ">> Epoch 35 finished \tANN training loss 0.853284\n",
            ">> Epoch 36 finished \tANN training loss 0.643309\n",
            ">> Epoch 37 finished \tANN training loss 0.657322\n",
            ">> Epoch 38 finished \tANN training loss 0.608522\n",
            ">> Epoch 39 finished \tANN training loss 0.771529\n",
            ">> Epoch 40 finished \tANN training loss 0.633999\n",
            ">> Epoch 41 finished \tANN training loss 0.637887\n",
            ">> Epoch 42 finished \tANN training loss 0.621865\n",
            ">> Epoch 43 finished \tANN training loss 0.574590\n",
            ">> Epoch 44 finished \tANN training loss 0.576875\n",
            ">> Epoch 45 finished \tANN training loss 0.799400\n",
            ">> Epoch 46 finished \tANN training loss 0.647421\n",
            ">> Epoch 47 finished \tANN training loss 0.547465\n",
            ">> Epoch 48 finished \tANN training loss 0.509092\n",
            ">> Epoch 49 finished \tANN training loss 0.594612\n",
            ">> Epoch 50 finished \tANN training loss 0.574606\n",
            ">> Epoch 51 finished \tANN training loss 0.569939\n",
            ">> Epoch 52 finished \tANN training loss 0.476568\n",
            ">> Epoch 53 finished \tANN training loss 0.539329\n",
            ">> Epoch 54 finished \tANN training loss 0.499898\n",
            ">> Epoch 55 finished \tANN training loss 0.544789\n",
            ">> Epoch 56 finished \tANN training loss 0.647368\n",
            ">> Epoch 57 finished \tANN training loss 0.969598\n",
            ">> Epoch 58 finished \tANN training loss 0.475547\n",
            ">> Epoch 59 finished \tANN training loss 0.454910\n",
            ">> Epoch 60 finished \tANN training loss 0.437104\n",
            ">> Epoch 61 finished \tANN training loss 0.424194\n",
            ">> Epoch 62 finished \tANN training loss 0.490134\n",
            ">> Epoch 63 finished \tANN training loss 0.397937\n",
            ">> Epoch 64 finished \tANN training loss 0.394233\n",
            ">> Epoch 65 finished \tANN training loss 0.392327\n",
            ">> Epoch 66 finished \tANN training loss 0.393688\n",
            ">> Epoch 67 finished \tANN training loss 0.492650\n",
            ">> Epoch 68 finished \tANN training loss 0.519179\n",
            ">> Epoch 69 finished \tANN training loss 0.419632\n",
            ">> Epoch 70 finished \tANN training loss 0.352470\n",
            ">> Epoch 71 finished \tANN training loss 0.350642\n",
            ">> Epoch 72 finished \tANN training loss 0.356442\n",
            ">> Epoch 73 finished \tANN training loss 0.337871\n",
            ">> Epoch 74 finished \tANN training loss 0.550652\n",
            ">> Epoch 75 finished \tANN training loss 0.502454\n",
            ">> Epoch 76 finished \tANN training loss 0.367960\n",
            ">> Epoch 77 finished \tANN training loss 0.311995\n",
            ">> Epoch 78 finished \tANN training loss 0.391720\n",
            ">> Epoch 79 finished \tANN training loss 0.340036\n",
            ">> Epoch 80 finished \tANN training loss 0.363924\n",
            ">> Epoch 81 finished \tANN training loss 0.345140\n",
            ">> Epoch 82 finished \tANN training loss 0.525064\n",
            ">> Epoch 83 finished \tANN training loss 0.409130\n",
            ">> Epoch 84 finished \tANN training loss 0.274633\n",
            ">> Epoch 85 finished \tANN training loss 0.299966\n",
            ">> Epoch 86 finished \tANN training loss 0.304363\n",
            ">> Epoch 87 finished \tANN training loss 0.264791\n",
            ">> Epoch 88 finished \tANN training loss 0.644932\n",
            ">> Epoch 89 finished \tANN training loss 0.233666\n",
            ">> Epoch 90 finished \tANN training loss 0.232599\n",
            ">> Epoch 91 finished \tANN training loss 0.279451\n",
            ">> Epoch 92 finished \tANN training loss 0.240310\n",
            ">> Epoch 93 finished \tANN training loss 0.241849\n",
            ">> Epoch 94 finished \tANN training loss 0.280076\n",
            ">> Epoch 95 finished \tANN training loss 0.206140\n",
            ">> Epoch 96 finished \tANN training loss 0.284892\n",
            ">> Epoch 97 finished \tANN training loss 0.316268\n",
            ">> Epoch 98 finished \tANN training loss 0.262847\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Epoch 99 finished \tANN training loss 0.204403\n",
            "[END] Fine tuning step\n",
            "\n",
            "Accuracy: 0.901961\n",
            "Confusion Matrix:\n",
            " [[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  6  0  2  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0]\n",
            " [ 0  0  2  0  0  0  0  0  0  0 13  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0]\n",
            " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  2  0  9  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0 13]]\n"
          ]
        }
      ],
      "source": [
        "#case 16\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(3529)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "\n",
        "\n",
        "dataset = pd.read_csv(\"Instruments.csv\")\n",
        "dataset = dataset.drop([\"File Name\"], axis=1)\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "dataset['Instrument'] = le.fit_transform(dataset['Instrument'])\n",
        "\n",
        "\n",
        "X = np.array(dataset.drop([\"Instrument\"], axis=1))\n",
        "Y = np.array(dataset.Instrument.values)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[256, 256, 256, 256, 256, 256],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.4,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='sigmoid',\n",
        "                                         dropout_p=0.05)\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print('\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa978cf2",
      "metadata": {
        "id": "aa978cf2",
        "outputId": "45b52445-ef9d-4bbe-e5ef-b76e7f13aaa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 41.792575\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 40.771735\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 40.879275\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 41.065100\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 41.151779\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 41.341957\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 41.493800\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 41.654394\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 41.835950\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 41.851513\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 14.581966\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 11.285711\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 10.320870\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 9.670917\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 9.090603\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 8.423300\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 8.043951\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 7.458773\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 7.287279\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 6.902758\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 6.242695\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 4.327269\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 3.471997\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 2.576168\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 2.113276\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 1.711740\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 1.451078\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 1.233816\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 1.042880\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.993318\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 4.023333\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 2.284643\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 1.906831\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 1.619697\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 1.306064\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 1.113005\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 1.012125\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.831073\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.770455\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.684564\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 4.326503\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 2.405709\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 1.889086\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 1.370159\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 1.126078\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.913198\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.778626\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.592356\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.489031\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.438090\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 3.242160\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 1.408722\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 1.224882\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.925179\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.891026\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.704861\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.677794\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.593075\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.470849\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.411954\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss 2.356841\n",
            ">> Epoch 1 finished \tANN training loss 1.889281\n",
            ">> Epoch 2 finished \tANN training loss 1.999467\n",
            ">> Epoch 3 finished \tANN training loss 1.702392\n",
            ">> Epoch 4 finished \tANN training loss 1.827894\n",
            ">> Epoch 5 finished \tANN training loss 1.534763\n",
            ">> Epoch 6 finished \tANN training loss 1.445119\n",
            ">> Epoch 7 finished \tANN training loss 1.779731\n",
            ">> Epoch 8 finished \tANN training loss 1.435609\n",
            ">> Epoch 9 finished \tANN training loss 1.403093\n",
            ">> Epoch 10 finished \tANN training loss 1.479311\n",
            ">> Epoch 11 finished \tANN training loss 1.348117\n",
            ">> Epoch 12 finished \tANN training loss 1.240289\n",
            ">> Epoch 13 finished \tANN training loss 1.413820\n",
            ">> Epoch 14 finished \tANN training loss 1.278798\n",
            ">> Epoch 15 finished \tANN training loss 1.160457\n",
            ">> Epoch 16 finished \tANN training loss 1.304313\n",
            ">> Epoch 17 finished \tANN training loss 1.144585\n",
            ">> Epoch 18 finished \tANN training loss 1.564302\n",
            ">> Epoch 19 finished \tANN training loss 1.122434\n",
            ">> Epoch 20 finished \tANN training loss 1.042869\n",
            ">> Epoch 21 finished \tANN training loss 1.183307\n",
            ">> Epoch 22 finished \tANN training loss 1.011542\n",
            ">> Epoch 23 finished \tANN training loss 1.055059\n",
            ">> Epoch 24 finished \tANN training loss 0.980324\n",
            ">> Epoch 25 finished \tANN training loss 0.842002\n",
            ">> Epoch 26 finished \tANN training loss 0.889686\n",
            ">> Epoch 27 finished \tANN training loss 0.988484\n",
            ">> Epoch 28 finished \tANN training loss 0.934812\n",
            ">> Epoch 29 finished \tANN training loss 0.891558\n",
            ">> Epoch 30 finished \tANN training loss 0.910291\n",
            ">> Epoch 31 finished \tANN training loss 0.785123\n",
            ">> Epoch 32 finished \tANN training loss 0.937582\n",
            ">> Epoch 33 finished \tANN training loss 0.728772\n",
            ">> Epoch 34 finished \tANN training loss 0.936973\n",
            ">> Epoch 35 finished \tANN training loss 0.762139\n",
            ">> Epoch 36 finished \tANN training loss 1.126121\n",
            ">> Epoch 37 finished \tANN training loss 0.665719\n",
            ">> Epoch 38 finished \tANN training loss 0.764321\n",
            ">> Epoch 39 finished \tANN training loss 0.691168\n",
            ">> Epoch 40 finished \tANN training loss 0.750967\n",
            ">> Epoch 41 finished \tANN training loss 0.808434\n",
            ">> Epoch 42 finished \tANN training loss 0.637628\n",
            ">> Epoch 43 finished \tANN training loss 0.754839\n",
            ">> Epoch 44 finished \tANN training loss 0.626977\n",
            ">> Epoch 45 finished \tANN training loss 0.561007\n",
            ">> Epoch 46 finished \tANN training loss 0.571904\n",
            ">> Epoch 47 finished \tANN training loss 0.574662\n",
            ">> Epoch 48 finished \tANN training loss 0.675314\n",
            ">> Epoch 49 finished \tANN training loss 0.540991\n",
            ">> Epoch 50 finished \tANN training loss 0.591618\n",
            ">> Epoch 51 finished \tANN training loss 0.667402\n",
            ">> Epoch 52 finished \tANN training loss 0.539540\n",
            ">> Epoch 53 finished \tANN training loss 0.634333\n",
            ">> Epoch 54 finished \tANN training loss 0.537280\n",
            ">> Epoch 55 finished \tANN training loss 0.536804\n",
            ">> Epoch 56 finished \tANN training loss 0.838150\n",
            ">> Epoch 57 finished \tANN training loss 0.619662\n",
            ">> Epoch 58 finished \tANN training loss 0.477288\n",
            ">> Epoch 59 finished \tANN training loss 0.541670\n",
            ">> Epoch 60 finished \tANN training loss 0.413264\n",
            ">> Epoch 61 finished \tANN training loss 0.478297\n",
            ">> Epoch 62 finished \tANN training loss 0.581394\n",
            ">> Epoch 63 finished \tANN training loss 0.444393\n",
            ">> Epoch 64 finished \tANN training loss 0.449002\n",
            ">> Epoch 65 finished \tANN training loss 0.554134\n",
            ">> Epoch 66 finished \tANN training loss 0.442626\n",
            ">> Epoch 67 finished \tANN training loss 0.521845\n",
            ">> Epoch 68 finished \tANN training loss 0.569024\n",
            ">> Epoch 69 finished \tANN training loss 0.399609\n",
            ">> Epoch 70 finished \tANN training loss 0.587007\n",
            ">> Epoch 71 finished \tANN training loss 0.453110\n",
            ">> Epoch 72 finished \tANN training loss 0.401042\n",
            ">> Epoch 73 finished \tANN training loss 0.480804\n",
            ">> Epoch 74 finished \tANN training loss 0.414249\n",
            ">> Epoch 75 finished \tANN training loss 0.371734\n",
            ">> Epoch 76 finished \tANN training loss 0.498519\n",
            ">> Epoch 77 finished \tANN training loss 0.400970\n",
            ">> Epoch 78 finished \tANN training loss 0.369111\n",
            ">> Epoch 79 finished \tANN training loss 0.349084\n",
            ">> Epoch 80 finished \tANN training loss 0.396247\n",
            ">> Epoch 81 finished \tANN training loss 0.417670\n",
            ">> Epoch 82 finished \tANN training loss 0.709744\n",
            ">> Epoch 83 finished \tANN training loss 0.351304\n",
            ">> Epoch 84 finished \tANN training loss 0.470447\n",
            ">> Epoch 85 finished \tANN training loss 0.330241\n",
            ">> Epoch 86 finished \tANN training loss 0.369712\n",
            ">> Epoch 87 finished \tANN training loss 0.404151\n",
            ">> Epoch 88 finished \tANN training loss 0.366452\n",
            ">> Epoch 89 finished \tANN training loss 0.327789\n",
            ">> Epoch 90 finished \tANN training loss 0.299704\n",
            ">> Epoch 91 finished \tANN training loss 0.388818\n",
            ">> Epoch 92 finished \tANN training loss 0.315336\n",
            ">> Epoch 93 finished \tANN training loss 0.521408\n",
            ">> Epoch 94 finished \tANN training loss 0.468917\n",
            ">> Epoch 95 finished \tANN training loss 0.313262\n",
            ">> Epoch 96 finished \tANN training loss 0.447776\n",
            ">> Epoch 97 finished \tANN training loss 0.357050\n",
            ">> Epoch 98 finished \tANN training loss 0.296343\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Epoch 99 finished \tANN training loss 0.333221\n",
            "[END] Fine tuning step\n",
            "\n",
            "Accuracy: 0.857843\n",
            "Confusion Matrix:\n",
            " [[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 10  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  6  0  2  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0 10  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0]\n",
            " [ 0  0  3  0  0  0  0  0  0  0 12  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0]\n",
            " [ 0  0  0  0  1  0  0  0  0  0  1  0  0  0  8  0  2]\n",
            " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  2  0  8  1]\n",
            " [ 0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  1 12]]\n"
          ]
        }
      ],
      "source": [
        "#case 17\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(3529)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "\n",
        "\n",
        "dataset = pd.read_csv(\"Instruments.csv\")\n",
        "dataset = dataset.drop([\"File Name\"], axis=1)\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "dataset['Instrument'] = le.fit_transform(dataset['Instrument'])\n",
        "\n",
        "\n",
        "X = np.array(dataset.drop([\"Instrument\"], axis=1))\n",
        "Y = np.array(dataset.Instrument.values)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[256, 256, 256, 256, 256, 256],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.4,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='sigmoid',\n",
        "                                         dropout_p=0.1)\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print('\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c81e8d03",
      "metadata": {
        "id": "c81e8d03",
        "outputId": "93c6f55c-9969-4091-f9b0-73f20935d763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 41.372756\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 40.476467\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 40.702153\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 41.071466\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 41.296782\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 41.597052\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 41.837017\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 42.108080\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 42.290347\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 42.388742\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 14.298517\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 11.045434\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 9.978397\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 9.239408\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 8.596379\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 7.899508\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 7.500735\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 6.909717\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 6.811239\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 6.425774\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 6.294147\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 3.999786\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 3.082825\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 2.855599\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 2.173448\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 1.733197\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 1.338001\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 1.153471\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.995697\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.872445\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 4.564561\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 2.602133\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 2.189684\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 1.826993\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 1.576019\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 1.354075\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 1.128998\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.916909\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.799442\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.650493\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 3.881838\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 2.328367\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 1.997225\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 1.697622\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 1.325599\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 1.037129\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.861931\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.751085\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.636184\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.554327\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 3.110528\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 1.473014\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 1.174214\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 0.989583\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 0.941347\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 0.749563\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 0.567083\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 0.489073\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 0.457342\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 0.397526\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss 2.533912\n",
            ">> Epoch 1 finished \tANN training loss 1.912662\n",
            ">> Epoch 2 finished \tANN training loss 2.138717\n",
            ">> Epoch 3 finished \tANN training loss 1.712893\n",
            ">> Epoch 4 finished \tANN training loss 1.925005\n",
            ">> Epoch 5 finished \tANN training loss 1.608649\n",
            ">> Epoch 6 finished \tANN training loss 1.566926\n",
            ">> Epoch 7 finished \tANN training loss 1.772526\n",
            ">> Epoch 8 finished \tANN training loss 1.534930\n",
            ">> Epoch 9 finished \tANN training loss 1.583749\n",
            ">> Epoch 10 finished \tANN training loss 1.472319\n",
            ">> Epoch 11 finished \tANN training loss 1.528329\n",
            ">> Epoch 12 finished \tANN training loss 1.366386\n",
            ">> Epoch 13 finished \tANN training loss 1.360620\n",
            ">> Epoch 14 finished \tANN training loss 1.489842\n",
            ">> Epoch 15 finished \tANN training loss 1.419135\n",
            ">> Epoch 16 finished \tANN training loss 1.276041\n",
            ">> Epoch 17 finished \tANN training loss 1.331768\n",
            ">> Epoch 18 finished \tANN training loss 1.273733\n",
            ">> Epoch 19 finished \tANN training loss 1.292297\n",
            ">> Epoch 20 finished \tANN training loss 1.261607\n",
            ">> Epoch 21 finished \tANN training loss 1.203192\n",
            ">> Epoch 22 finished \tANN training loss 1.264314\n",
            ">> Epoch 23 finished \tANN training loss 1.126404\n",
            ">> Epoch 24 finished \tANN training loss 1.070546\n",
            ">> Epoch 25 finished \tANN training loss 1.009856\n",
            ">> Epoch 26 finished \tANN training loss 1.154775\n",
            ">> Epoch 27 finished \tANN training loss 1.033245\n",
            ">> Epoch 28 finished \tANN training loss 1.028367\n",
            ">> Epoch 29 finished \tANN training loss 1.117733\n",
            ">> Epoch 30 finished \tANN training loss 1.101441\n",
            ">> Epoch 31 finished \tANN training loss 0.978223\n",
            ">> Epoch 32 finished \tANN training loss 1.043937\n",
            ">> Epoch 33 finished \tANN training loss 0.928538\n",
            ">> Epoch 34 finished \tANN training loss 0.919770\n",
            ">> Epoch 35 finished \tANN training loss 0.917674\n",
            ">> Epoch 36 finished \tANN training loss 0.898565\n",
            ">> Epoch 37 finished \tANN training loss 0.925438\n",
            ">> Epoch 38 finished \tANN training loss 0.904800\n",
            ">> Epoch 39 finished \tANN training loss 0.904152\n",
            ">> Epoch 40 finished \tANN training loss 0.818319\n",
            ">> Epoch 41 finished \tANN training loss 0.825659\n",
            ">> Epoch 42 finished \tANN training loss 0.835696\n",
            ">> Epoch 43 finished \tANN training loss 0.792625\n",
            ">> Epoch 44 finished \tANN training loss 0.844598\n",
            ">> Epoch 45 finished \tANN training loss 0.833484\n",
            ">> Epoch 46 finished \tANN training loss 0.889358\n",
            ">> Epoch 47 finished \tANN training loss 0.768787\n",
            ">> Epoch 48 finished \tANN training loss 0.791587\n",
            ">> Epoch 49 finished \tANN training loss 0.765142\n",
            ">> Epoch 50 finished \tANN training loss 0.845533\n",
            ">> Epoch 51 finished \tANN training loss 0.788608\n",
            ">> Epoch 52 finished \tANN training loss 0.728863\n",
            ">> Epoch 53 finished \tANN training loss 0.947965\n",
            ">> Epoch 54 finished \tANN training loss 0.817560\n",
            ">> Epoch 55 finished \tANN training loss 0.887742\n",
            ">> Epoch 56 finished \tANN training loss 0.787665\n",
            ">> Epoch 57 finished \tANN training loss 0.929358\n",
            ">> Epoch 58 finished \tANN training loss 0.829298\n",
            ">> Epoch 59 finished \tANN training loss 0.786177\n",
            ">> Epoch 60 finished \tANN training loss 0.722860\n",
            ">> Epoch 61 finished \tANN training loss 0.798352\n",
            ">> Epoch 62 finished \tANN training loss 0.775610\n",
            ">> Epoch 63 finished \tANN training loss 0.687135\n",
            ">> Epoch 64 finished \tANN training loss 0.740055\n",
            ">> Epoch 65 finished \tANN training loss 0.640857\n",
            ">> Epoch 66 finished \tANN training loss 0.623001\n",
            ">> Epoch 67 finished \tANN training loss 0.669290\n",
            ">> Epoch 68 finished \tANN training loss 0.640343\n",
            ">> Epoch 69 finished \tANN training loss 0.657516\n",
            ">> Epoch 70 finished \tANN training loss 0.752479\n",
            ">> Epoch 71 finished \tANN training loss 0.640654\n",
            ">> Epoch 72 finished \tANN training loss 0.590965\n",
            ">> Epoch 73 finished \tANN training loss 0.652863\n",
            ">> Epoch 74 finished \tANN training loss 0.683715\n",
            ">> Epoch 75 finished \tANN training loss 0.626392\n",
            ">> Epoch 76 finished \tANN training loss 0.625947\n",
            ">> Epoch 77 finished \tANN training loss 0.628208\n",
            ">> Epoch 78 finished \tANN training loss 0.580186\n",
            ">> Epoch 79 finished \tANN training loss 0.620502\n",
            ">> Epoch 80 finished \tANN training loss 0.785973\n",
            ">> Epoch 81 finished \tANN training loss 0.571416\n",
            ">> Epoch 82 finished \tANN training loss 0.705353\n",
            ">> Epoch 83 finished \tANN training loss 0.579118\n",
            ">> Epoch 84 finished \tANN training loss 0.630101\n",
            ">> Epoch 85 finished \tANN training loss 0.548272\n",
            ">> Epoch 86 finished \tANN training loss 0.559437\n",
            ">> Epoch 87 finished \tANN training loss 0.541931\n",
            ">> Epoch 88 finished \tANN training loss 0.663547\n",
            ">> Epoch 89 finished \tANN training loss 0.570517\n",
            ">> Epoch 90 finished \tANN training loss 0.529368\n",
            ">> Epoch 91 finished \tANN training loss 0.550965\n",
            ">> Epoch 92 finished \tANN training loss 0.508707\n",
            ">> Epoch 93 finished \tANN training loss 0.563552\n",
            ">> Epoch 94 finished \tANN training loss 0.550841\n",
            ">> Epoch 95 finished \tANN training loss 0.530294\n",
            ">> Epoch 96 finished \tANN training loss 0.535948\n",
            ">> Epoch 97 finished \tANN training loss 0.535212\n",
            ">> Epoch 98 finished \tANN training loss 0.518781\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Epoch 99 finished \tANN training loss 0.551749\n",
            "[END] Fine tuning step\n",
            "\n",
            "Accuracy: 0.843137\n",
            "Confusion Matrix:\n",
            " [[18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  8  0  3  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  6  0  2  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0 10  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  1  0  0  0  0  5  0  0  0  0  0  0  0]\n",
            " [ 0  0  1  0  1  0  0  0  0  0 13  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  0 10  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0  6  0  5]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  8  1]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0 13]]\n"
          ]
        }
      ],
      "source": [
        "#case 18\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(3529)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "\n",
        "\n",
        "dataset = pd.read_csv(\"Instruments.csv\")\n",
        "dataset = dataset.drop([\"File Name\"], axis=1)\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "dataset['Instrument'] = le.fit_transform(dataset['Instrument'])\n",
        "\n",
        "\n",
        "X = np.array(dataset.drop([\"Instrument\"], axis=1))\n",
        "Y = np.array(dataset.Instrument.values)\n",
        "\n",
        "ss=StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[256, 256, 256, 256, 256, 256],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.4,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='sigmoid',\n",
        "                                         dropout_p=0.2)\n",
        "classifier.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print('\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}